
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An interactive python terminal UI wrapper for Mango Tree analyzers.">
      
      
        <meta name="author" content="CIB Mango Tree">
      
      
        <link rel="canonical" href="https://cibmangotree.org/reference/tokenizer/">
      
      
        <link rel="prev" href="../testing/">
      
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Tokenizer - CIB Mango Tree</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#services.tokenizer.core" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="CIB Mango Tree" class="md-header__button md-logo" aria-label="CIB Mango Tree" data-md-component="logo">
      
  <img src="../../img/favicon.ico" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CIB Mango Tree
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tokenizer
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/civictechdc/mango-tango-cli" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../.." class="md-tabs__link">
          
  
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../guides/get-started/overview/" class="md-tabs__link">
          
  
  
  Guides

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../analyzer_interface/" class="md-tabs__link">
          
  
  
  Reference (CLI)

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="CIB Mango Tree" class="md-nav__button md-logo" aria-label="CIB Mango Tree" data-md-component="logo">
      
  <img src="../../img/favicon.ico" alt="logo">

    </a>
    CIB Mango Tree
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/civictechdc/mango-tango-cli" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Home
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    About
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../license/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    License
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Guides
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Guides
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Getting Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/get-started/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/get-started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Contributing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/contributing/contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contributor Workflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/contributing/analyzers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Implementing Analyzers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_2_3" id="__nav_2_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Dashboards
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Dashboards
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/contributing/dashboards/shiny/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Shiny
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/contributing/dashboards/react/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    React (WIP)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/contributing/logging/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Logging
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/contributing/testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Design Philosophy
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Design Philosophy
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/design-philosophy/architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/design-philosophy/core-domain/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Core Domain
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/design-philosophy/edge-domain/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Edge Domain
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/design-philosophy/content-domain/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Content Domain
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Reference (CLI)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reference (CLI)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../analyzer_interface/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Analyzer Interface
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../components/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Components
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../app/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    App
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../preprocessing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Preprocessing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../terminal_tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Terminal Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../importing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Importing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../meta/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Meta
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../storage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Storage
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Tokenizer
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Tokenizer
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#services.tokenizer.core" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;core
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" core">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;AbstractTokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" AbstractTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __init__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.__init__(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.config" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.tokenize" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;tokenize
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" tokenize">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.tokenize(text)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;text
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.CaseHandling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CaseHandling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.LanguageFamily" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LanguageFamily
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenType" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenType
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenizerConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenizerConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.case_handling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;case_handling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.extract_cashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_cashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.extract_hashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_hashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.extract_mentions" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_mentions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.fallback_language_family" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;fallback_language_family
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_emails" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emails
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_emoji" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emoji
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_numeric" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_numeric
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_punctuation" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_punctuation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_urls" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_urls
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.max_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;max_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.min_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;min_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.normalize_unicode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;normalize_unicode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.strip_whitespace" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;strip_whitespace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;base
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" base">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;AbstractTokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" AbstractTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.__init__(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.config" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.tokenize" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;tokenize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.tokenize(text)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;text
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;types
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.CaseHandling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CaseHandling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.LanguageFamily" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LanguageFamily
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenType" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenType
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenizerConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenizerConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.case_handling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;case_handling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.extract_cashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_cashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.extract_hashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_hashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.extract_mentions" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_mentions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.fallback_language_family" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;fallback_language_family
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_emails" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emails
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_emoji" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emoji
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_numeric" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_numeric
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_punctuation" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_punctuation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_urls" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_urls
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.max_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;max_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.min_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;min_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.normalize_unicode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;normalize_unicode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.strip_whitespace" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;strip_whitespace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#services.tokenizer.basic" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;basic
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" basic">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BasicTokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BasicTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __init__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer.__init__(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer.tokenize" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;tokenize
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" tokenize">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer.tokenize(text)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;text
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenizerConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenizerConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.case_handling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;case_handling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.extract_cashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_cashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.extract_hashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_hashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.extract_mentions" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_mentions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.fallback_language_family" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;fallback_language_family
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_emails" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emails
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_emoji" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emoji
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_numeric" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_numeric
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_punctuation" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_punctuation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_urls" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_urls
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.max_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;max_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.min_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;min_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.normalize_unicode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;normalize_unicode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.strip_whitespace" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;strip_whitespace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.create_basic_tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;create_basic_tokenizer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.get_patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_patterns
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;patterns
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" patterns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenizerPatterns
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenizerPatterns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_comprehensive_pattern" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_comprehensive_pattern
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_comprehensive_pattern(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_exclusion_pattern" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_exclusion_pattern
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_exclusion_pattern(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_pattern" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_pattern
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_pattern(pattern_name)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pattern_name
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.list_patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;list_patterns
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.get_patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_patterns
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenize_text" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tokenize_text
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;tokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" tokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BasicTokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BasicTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer.__init__(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer.tokenize" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;tokenize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer.tokenize(text)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;text
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#services.tokenizer.core" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;core
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" core">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;AbstractTokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" AbstractTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __init__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.__init__(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.config" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.tokenize" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;tokenize
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" tokenize">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.AbstractTokenizer.tokenize(text)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;text
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.CaseHandling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CaseHandling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.LanguageFamily" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LanguageFamily
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenType" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenType
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenizerConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenizerConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.case_handling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;case_handling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.extract_cashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_cashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.extract_hashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_hashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.extract_mentions" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_mentions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.fallback_language_family" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;fallback_language_family
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_emails" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emails
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_emoji" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emoji
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_numeric" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_numeric
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_punctuation" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_punctuation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.include_urls" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_urls
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.max_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;max_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.min_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;min_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.normalize_unicode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;normalize_unicode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.TokenizerConfig.strip_whitespace" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;strip_whitespace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;base
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" base">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;AbstractTokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" AbstractTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.__init__(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.config" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.tokenize" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;tokenize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.base.AbstractTokenizer.tokenize(text)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;text
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;types
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.CaseHandling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CaseHandling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.LanguageFamily" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LanguageFamily
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenType" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenType
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenizerConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenizerConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.case_handling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;case_handling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.extract_cashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_cashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.extract_hashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_hashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.extract_mentions" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_mentions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.fallback_language_family" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;fallback_language_family
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_emails" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emails
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_emoji" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emoji
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_numeric" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_numeric
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_punctuation" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_punctuation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.include_urls" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_urls
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.max_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;max_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.min_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;min_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.normalize_unicode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;normalize_unicode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.core.types.TokenizerConfig.strip_whitespace" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;strip_whitespace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#services.tokenizer.basic" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;basic
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" basic">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BasicTokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BasicTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __init__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer.__init__(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer.tokenize" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;tokenize
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" tokenize">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.BasicTokenizer.tokenize(text)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;text
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenizerConfig
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenizerConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.case_handling" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;case_handling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.extract_cashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_cashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.extract_hashtags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_hashtags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.extract_mentions" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;extract_mentions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.fallback_language_family" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;fallback_language_family
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_emails" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emails
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_emoji" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_emoji
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_numeric" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_numeric
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_punctuation" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_punctuation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.include_urls" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;include_urls
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.max_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;max_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.min_token_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;min_token_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.normalize_unicode" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;normalize_unicode
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.TokenizerConfig.strip_whitespace" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;strip_whitespace
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.create_basic_tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;create_basic_tokenizer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.get_patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_patterns
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;patterns
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" patterns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenizerPatterns
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenizerPatterns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_comprehensive_pattern" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_comprehensive_pattern
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_comprehensive_pattern(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_exclusion_pattern" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_exclusion_pattern
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_exclusion_pattern(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_pattern" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_pattern
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_pattern(pattern_name)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pattern_name
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.TokenizerPatterns.list_patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;list_patterns
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.patterns.get_patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_patterns
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenize_text" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;tokenize_text
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;tokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" tokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BasicTokenizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BasicTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer.__init__(config)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;config
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer.tokenize" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;tokenize
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#services.tokenizer.basic.tokenizer.BasicTokenizer.tokenize(text)" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;text
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
                




              
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>Tokenizer</h1>

<div class="doc doc-object doc-module">



<h2 id="services.tokenizer.core" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <code>services.tokenizer.core</code>


</h2>

    <div class="doc doc-contents first">

        <p>Core tokenizer components.</p>
<p>Exports:
- AbstractTokenizer
- TokenizerConfig
- TokenList
- LanguageFamily
- TokenType
- CaseHandling</p>


<details class="intended-usage" open>
  <summary>Intended usage</summary>
  <p>from services.tokenizer.core import (
    AbstractTokenizer,
    TokenizerConfig,
    TokenList,
    LanguageFamily,
    TokenType,
    CaseHandling,
)</p>
</details>





<p><span class="doc-section-title">Modules:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-module&quot;&gt;&lt;/code&gt;            &lt;code&gt;base&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.base&lt;/code&gt;)" href="#services.tokenizer.core.base">base</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>AbstractTokenizer abstract base class</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-module&quot;&gt;&lt;/code&gt;            &lt;code&gt;types&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types&lt;/code&gt;)" href="#services.tokenizer.core.types">types</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>TokenizerConfig, enums, and shared types</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>






<p><span class="doc-section-title">Classes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;AbstractTokenizer&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.AbstractTokenizer&lt;/code&gt;)" href="#services.tokenizer.core.AbstractTokenizer">AbstractTokenizer</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Abstract base class for all tokenizer implementations.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;CaseHandling&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.CaseHandling&lt;/code&gt;)" href="#services.tokenizer.core.CaseHandling">CaseHandling</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>How to handle character case during tokenization.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;LanguageFamily&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.LanguageFamily&lt;/code&gt;)" href="#services.tokenizer.core.LanguageFamily">LanguageFamily</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Language families that affect tokenization strategies.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenType&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.TokenType&lt;/code&gt;)" href="#services.tokenizer.core.TokenType">TokenType</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Types of tokens that can be extracted.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.core.TokenizerConfig">TokenizerConfig</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Configuration for tokenizer behavior.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>







<div class="doc doc-children">







<div class="doc doc-object doc-class">



<h3 id="services.tokenizer.core.AbstractTokenizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>AbstractTokenizer</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for all tokenizer implementations.</p>
<p>This class defines the core interface that all tokenizer plugins must implement.
It provides a clean contract for tokenization operations while allowing for
different implementation strategies.</p>












<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.AbstractTokenizer.__init__&lt;/code&gt;)" href="#services.tokenizer.core.AbstractTokenizer.__init__">__init__</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Initialize the tokenizer with configuration.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-abstractmethod&quot;&gt;&lt;code&gt;abstractmethod&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.AbstractTokenizer.tokenize&lt;/code&gt;)" href="#services.tokenizer.core.AbstractTokenizer.tokenize">tokenize</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Tokenize input text into a list of tokens.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>




<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-property&quot;&gt;&lt;code&gt;property&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.AbstractTokenizer.config&lt;/code&gt;)" href="#services.tokenizer.core.AbstractTokenizer.config">config</a></code></td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig">TokenizerConfig</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Get the current tokenizer configuration.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AbstractTokenizer</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base class for all tokenizer implementations.</span>

<span class="sd">    This class defines the core interface that all tokenizer plugins must implement.</span>
<span class="sd">    It provides a clean contract for tokenization operations while allowing for</span>
<span class="sd">    different implementation strategies.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TokenizerConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the tokenizer with configuration.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: Tokenizer configuration. If None, default config will be used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="n">config</span> <span class="ow">or</span> <span class="n">TokenizerConfig</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenizerConfig</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current tokenizer configuration.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tokenize input text into a list of tokens.</span>

<span class="sd">        This is the main tokenization method that all implementations must provide.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Input text to tokenize</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of tokens extracted from the input text</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_preprocess_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply preprocessing to text before tokenization.</span>

<span class="sd">        This method applies configuration-based preprocessing such as</span>
<span class="sd">        case handling and Unicode normalization.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Input text to preprocess</span>

<span class="sd">        Returns:</span>
<span class="sd">            Preprocessed text</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">text</span>

        <span class="c1"># Apply Unicode normalization</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">normalize_unicode</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">unicodedata</span>

            <span class="n">text</span> <span class="o">=</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s2">&quot;NFKC&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

        <span class="c1"># Apply case handling</span>
        <span class="kn">from</span> <span class="nn">.types</span> <span class="kn">import</span> <span class="n">CaseHandling</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">case_handling</span> <span class="o">==</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">LOWERCASE</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">case_handling</span> <span class="o">==</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">UPPERCASE</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">case_handling</span> <span class="o">==</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">NORMALIZE</span><span class="p">:</span>
            <span class="c1"># TODO: Implement proper noun detection for smart normalization</span>
            <span class="c1"># Currently using simple lowercase as a placeholder</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">text</span>

    <span class="k">def</span> <span class="nf">_postprocess_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="n">TokenList</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply post-processing to extracted tokens.</span>

<span class="sd">        This method applies configuration-based filtering and cleanup</span>
<span class="sd">        to the token list.</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens: List of raw tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            Processed token list</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tokens</span>

        <span class="n">processed_tokens</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="c1"># Strip whitespace if configured</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">strip_whitespace</span><span class="p">:</span>
                <span class="n">token</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

            <span class="c1"># Skip empty tokens</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># Filter emojis if not included</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">include_emoji</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_emoji</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="c1"># Apply length filtering</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">min_token_length</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">max_token_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">max_token_length</span>
            <span class="p">):</span>
                <span class="k">continue</span>

            <span class="n">processed_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">processed_tokens</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_emoji</span><span class="p">(</span><span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if a token is an emoji character.</span>

<span class="sd">        Args:</span>
<span class="sd">            token: Token to check</span>

<span class="sd">        Returns:</span>
<span class="sd">            True if the token is an emoji, False otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Accept sequences made of emoji code points plus common modifiers</span>
        <span class="n">EMOJI_RANGES</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="mh">0x1F600</span><span class="p">,</span> <span class="mh">0x1F64F</span><span class="p">),</span>  <span class="c1"># Emoticons</span>
            <span class="p">(</span><span class="mh">0x1F300</span><span class="p">,</span> <span class="mh">0x1F5FF</span><span class="p">),</span>  <span class="c1"># Misc Symbols &amp; Pictographs</span>
            <span class="p">(</span><span class="mh">0x1F680</span><span class="p">,</span> <span class="mh">0x1F6FF</span><span class="p">),</span>  <span class="c1"># Transport &amp; Map</span>
            <span class="p">(</span><span class="mh">0x1F1E6</span><span class="p">,</span> <span class="mh">0x1F1FF</span><span class="p">),</span>  <span class="c1"># Regional Indicators</span>
            <span class="p">(</span><span class="mh">0x2600</span><span class="p">,</span> <span class="mh">0x26FF</span><span class="p">),</span>  <span class="c1"># Misc symbols</span>
            <span class="p">(</span><span class="mh">0x2700</span><span class="p">,</span> <span class="mh">0x27BF</span><span class="p">),</span>  <span class="c1"># Dingbats</span>
            <span class="p">(</span><span class="mh">0x1F900</span><span class="p">,</span> <span class="mh">0x1F9FF</span><span class="p">),</span>  <span class="c1"># Supplemental Symbols &amp; Pictographs</span>
            <span class="p">(</span><span class="mh">0x1FA70</span><span class="p">,</span> <span class="mh">0x1FAFF</span><span class="p">),</span>  <span class="c1"># Symbols &amp; Pictographs Extended-A</span>
        <span class="p">)</span>
        <span class="n">MODIFIERS</span> <span class="o">=</span> <span class="p">{</span><span class="mh">0x200D</span><span class="p">,</span> <span class="mh">0xFE0E</span><span class="p">,</span> <span class="mh">0xFE0F</span><span class="p">}</span>  <span class="c1"># ZWJ, VS15, VS16</span>
        <span class="n">SKIN_TONE</span> <span class="o">=</span> <span class="p">(</span><span class="mh">0x1F3FB</span><span class="p">,</span> <span class="mh">0x1F3FF</span><span class="p">)</span>
        <span class="n">TAGS</span> <span class="o">=</span> <span class="p">(</span><span class="mh">0xE0020</span><span class="p">,</span> <span class="mh">0xE007F</span><span class="p">)</span>  <span class="c1"># Emoji tag sequences</span>

        <span class="k">def</span> <span class="nf">in_any_range</span><span class="p">(</span><span class="n">cp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ranges</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">ranges</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">cp</span> <span class="o">&lt;=</span> <span class="n">b</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">def</span> <span class="nf">is_modifier</span><span class="p">(</span><span class="n">cp</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">cp</span> <span class="ow">in</span> <span class="n">MODIFIERS</span>
                <span class="ow">or</span> <span class="n">SKIN_TONE</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">cp</span> <span class="o">&lt;=</span> <span class="n">SKIN_TONE</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="ow">or</span> <span class="n">TAGS</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">cp</span> <span class="o">&lt;=</span> <span class="n">TAGS</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
            <span class="n">cp</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">in_any_range</span><span class="p">(</span><span class="n">cp</span><span class="p">,</span> <span class="n">EMOJI_RANGES</span><span class="p">)</span> <span class="ow">or</span> <span class="n">is_modifier</span><span class="p">(</span><span class="n">cp</span><span class="p">)):</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-function">


<h4 id="services.tokenizer.core.AbstractTokenizer.__init__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize the tokenizer with configuration.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h5 id="services.tokenizer.core.AbstractTokenizer.__init__(config)" class="doc doc-heading doc-heading-parameter">                  <code>config</code>
</h5>            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig">TokenizerConfig</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tokenizer configuration. If None, default config will be used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/core/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TokenizerConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize the tokenizer with configuration.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: Tokenizer configuration. If None, default config will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="n">config</span> <span class="ow">or</span> <span class="n">TokenizerConfig</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.AbstractTokenizer.config" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">config</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Get the current tokenizer configuration.</p>

    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="services.tokenizer.core.AbstractTokenizer.tokenize" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Tokenize input text into a list of tokens.</p>
<p>This is the main tokenization method that all implementations must provide.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h5 id="services.tokenizer.core.AbstractTokenizer.tokenize(text)" class="doc doc-heading doc-heading-parameter">                  <code>text</code>
</h5>            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input text to tokenize</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="services.tokenizer.core.types.TokenList">TokenList</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of tokens extracted from the input text</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/core/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenize input text into a list of tokens.</span>

<span class="sd">    This is the main tokenization method that all implementations must provide.</span>

<span class="sd">    Args:</span>
<span class="sd">        text: Input text to tokenize</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of tokens extracted from the input text</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>






<div class="doc doc-object doc-class">



<h3 id="services.tokenizer.core.CaseHandling" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>CaseHandling</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="enum.Enum">Enum</span></code></p>



        <p>How to handle character case during tokenization.</p>













              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CaseHandling</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;How to handle character case during tokenization.&quot;&quot;&quot;</span>

    <span class="n">PRESERVE</span> <span class="o">=</span> <span class="s2">&quot;preserve&quot;</span>  <span class="c1"># Keep original case</span>
    <span class="n">LOWERCASE</span> <span class="o">=</span> <span class="s2">&quot;lowercase&quot;</span>  <span class="c1"># Convert to lowercase</span>
    <span class="n">UPPERCASE</span> <span class="o">=</span> <span class="s2">&quot;uppercase&quot;</span>  <span class="c1"># Convert to uppercase</span>
    <span class="n">NORMALIZE</span> <span class="o">=</span> <span class="s2">&quot;normalize&quot;</span>  <span class="c1"># Smart case normalization</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">





  </div>

    </div>

</div>






<div class="doc doc-object doc-class">



<h3 id="services.tokenizer.core.LanguageFamily" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>LanguageFamily</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="str">str</span></code>, <code><span title="enum.Enum">Enum</span></code></p>



        <p>Language families that affect tokenization strategies.</p>













              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LanguageFamily</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Language families that affect tokenization strategies.&quot;&quot;&quot;</span>

    <span class="n">LATIN</span> <span class="o">=</span> <span class="s2">&quot;latin&quot;</span>  <span class="c1"># Space-separated languages (English, French, etc.)</span>
    <span class="n">CJK</span> <span class="o">=</span> <span class="s2">&quot;cjk&quot;</span>  <span class="c1"># Chinese, Japanese, Korean</span>
    <span class="n">ARABIC</span> <span class="o">=</span> <span class="s2">&quot;arabic&quot;</span>  <span class="c1"># Arabic script languages</span>
    <span class="n">MIXED</span> <span class="o">=</span> <span class="s2">&quot;mixed&quot;</span>  <span class="c1"># Mixed content requiring multiple strategies</span>
    <span class="n">UNKNOWN</span> <span class="o">=</span> <span class="s2">&quot;unknown&quot;</span>  <span class="c1"># Language detection failed or not performed</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">





  </div>

    </div>

</div>






<div class="doc doc-object doc-class">



<h3 id="services.tokenizer.core.TokenType" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>TokenType</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="str">str</span></code>, <code><span title="enum.Enum">Enum</span></code></p>



        <p>Types of tokens that can be extracted.</p>













              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TokenType</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Types of tokens that can be extracted.&quot;&quot;&quot;</span>

    <span class="n">WORD</span> <span class="o">=</span> <span class="s2">&quot;word&quot;</span>  <span class="c1"># Regular words</span>
    <span class="n">PUNCTUATION</span> <span class="o">=</span> <span class="s2">&quot;punctuation&quot;</span>  <span class="c1"># Punctuation marks</span>
    <span class="n">NUMERIC</span> <span class="o">=</span> <span class="s2">&quot;numeric&quot;</span>  <span class="c1"># Numbers</span>
    <span class="n">EMOJI</span> <span class="o">=</span> <span class="s2">&quot;emoji&quot;</span>  <span class="c1"># Emoji characters</span>
    <span class="n">HASHTAG</span> <span class="o">=</span> <span class="s2">&quot;hashtag&quot;</span>  <span class="c1"># Social media hashtags</span>
    <span class="n">MENTION</span> <span class="o">=</span> <span class="s2">&quot;mention&quot;</span>  <span class="c1"># Social media mentions</span>
    <span class="n">URL</span> <span class="o">=</span> <span class="s2">&quot;url&quot;</span>  <span class="c1"># URLs and links</span>
    <span class="n">EMAIL</span> <span class="o">=</span> <span class="s2">&quot;email&quot;</span>  <span class="c1"># Email addresses</span>
    <span class="n">WHITESPACE</span> <span class="o">=</span> <span class="s2">&quot;whitespace&quot;</span>  <span class="c1"># Whitespace (when preserved)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">





  </div>

    </div>

</div>






<div class="doc doc-object doc-class">



<h3 id="services.tokenizer.core.TokenizerConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>TokenizerConfig</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="pydantic.BaseModel">BaseModel</span></code></p>

        <p>Configuration for tokenizer behavior.</p>
<p>Controls all aspects of text tokenization including script handling,
social media entity processing, and output formatting.</p>
<p>Social Media Entity Behavior:
- extract_hashtags/extract_mentions: When False, splits into component words
- include_urls/include_emails: When False, completely excludes (no fragmentation)</p>

    

        <p>Fields:</p>
        <ul>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;fallback_language_family&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LanguageFamily&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MIXED&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.fallback_language_family&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.fallback_language_family">fallback_language_family</a></code>
                (<code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;LanguageFamily&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.LanguageFamily&lt;/code&gt;)" href="#services.tokenizer.core.types.LanguageFamily">LanguageFamily</a></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_punctuation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_punctuation&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_punctuation">include_punctuation</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_numeric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_numeric&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_numeric">include_numeric</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_emoji&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_emoji&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_emoji">include_emoji</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;case_handling&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CaseHandling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LOWERCASE&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.case_handling&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.case_handling">case_handling</a></code>
                (<code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;CaseHandling&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.CaseHandling&lt;/code&gt;)" href="#services.tokenizer.core.types.CaseHandling">CaseHandling</a></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;normalize_unicode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.normalize_unicode&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.normalize_unicode">normalize_unicode</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_hashtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_hashtags&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_hashtags">extract_hashtags</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_mentions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_mentions&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_mentions">extract_mentions</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_cashtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_cashtags&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_cashtags">extract_cashtags</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_urls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_urls&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_urls">include_urls</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_emails&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_emails&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_emails">include_emails</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;min_token_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.min_token_length&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.min_token_length">min_token_length</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;max_token_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.max_token_length&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.max_token_length">max_token_length</a></code>
                (<code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;strip_whitespace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.strip_whitespace&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.strip_whitespace">strip_whitespace</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
        </ul>


              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TokenizerConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for tokenizer behavior.</span>

<span class="sd">    Controls all aspects of text tokenization including script handling,</span>
<span class="sd">    social media entity processing, and output formatting.</span>

<span class="sd">    Social Media Entity Behavior:</span>
<span class="sd">    - extract_hashtags/extract_mentions: When False, splits into component words</span>
<span class="sd">    - include_urls/include_emails: When False, completely excludes (no fragmentation)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Language detection settings</span>
    <span class="n">fallback_language_family</span><span class="p">:</span> <span class="n">LanguageFamily</span> <span class="o">=</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Default language family when detection fails or mixed content is found.&quot;&quot;&quot;</span>

    <span class="c1"># Token type filtering</span>
    <span class="n">include_punctuation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include punctuation marks as separate tokens.&quot;&quot;&quot;</span>

    <span class="n">include_numeric</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include numeric tokens (integers, decimals, etc.).&quot;&quot;&quot;</span>

    <span class="n">include_emoji</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include emoji characters as tokens.&quot;&quot;&quot;</span>

    <span class="c1"># Text preprocessing</span>
    <span class="n">case_handling</span><span class="p">:</span> <span class="n">CaseHandling</span> <span class="o">=</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">LOWERCASE</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;How to handle character case during tokenization.&quot;&quot;&quot;</span>

    <span class="n">normalize_unicode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to apply Unicode NFKC normalization. Default False to preserve unicode tricks for bot detection.&quot;&quot;&quot;</span>

    <span class="c1"># Social media features</span>
    <span class="n">extract_hashtags</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve hashtags as single tokens. If False, splits into component words.&quot;&quot;&quot;</span>

    <span class="n">extract_mentions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve @mentions as single tokens. If False, splits into component words.&quot;&quot;&quot;</span>

    <span class="n">extract_cashtags</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve cashtags ($AAPL) as single tokens. If False, splits into components.&quot;&quot;&quot;</span>

    <span class="n">include_urls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include URLs as tokens. If False, URLs are completely excluded (not fragmented).&quot;&quot;&quot;</span>

    <span class="n">include_emails</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include email addresses as tokens. If False, emails are completely excluded (not fragmented).&quot;&quot;&quot;</span>

    <span class="c1"># Output formatting</span>
    <span class="n">min_token_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Minimum length for tokens to be included in output.&quot;&quot;&quot;</span>

    <span class="n">max_token_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Maximum length for tokens. If None, no length limit is applied.&quot;&quot;&quot;</span>

    <span class="n">strip_whitespace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to strip leading/trailing whitespace from tokens.&quot;&quot;&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>


<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.case_handling" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">case_handling</span> <span class="o">=</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">LOWERCASE</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>How to handle character case during tokenization.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.extract_cashtags" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_cashtags</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to preserve cashtags ($AAPL) as single tokens. If False, splits into components.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.extract_hashtags" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_hashtags</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to preserve hashtags as single tokens. If False, splits into component words.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.extract_mentions" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_mentions</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to preserve @mentions as single tokens. If False, splits into component words.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.fallback_language_family" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">fallback_language_family</span> <span class="o">=</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Default language family when detection fails or mixed content is found.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.include_emails" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_emails</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include email addresses as tokens. If False, emails are completely excluded (not fragmented).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.include_emoji" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_emoji</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include emoji characters as tokens.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.include_numeric" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_numeric</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include numeric tokens (integers, decimals, etc.).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.include_punctuation" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_punctuation</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include punctuation marks as separate tokens.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.include_urls" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_urls</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include URLs as tokens. If False, URLs are completely excluded (not fragmented).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.max_token_length" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">max_token_length</span> <span class="o">=</span> <span class="kc">None</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Maximum length for tokens. If None, no length limit is applied.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.min_token_length" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">min_token_length</span> <span class="o">=</span> <span class="mi">1</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Minimum length for tokens to be included in output.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.normalize_unicode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">normalize_unicode</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to apply Unicode NFKC normalization. Default False to preserve unicode tricks for bot detection.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.core.TokenizerConfig.strip_whitespace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">strip_whitespace</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to strip leading/trailing whitespace from tokens.</p>

    </div>

</div>




  </div>

    </div>

</div>






<div class="doc doc-object doc-module">



<h3 id="services.tokenizer.core.base" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <code>base</code>


</h3>

    <div class="doc doc-contents ">

        <p>AbstractTokenizer abstract base class</p>
<p>This module contains the abstract base class that defines
the interface for all tokenizer implementations.</p>










<p><span class="doc-section-title">Classes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;AbstractTokenizer&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.base.AbstractTokenizer&lt;/code&gt;)" href="#services.tokenizer.core.base.AbstractTokenizer">AbstractTokenizer</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Abstract base class for all tokenizer implementations.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>







<div class="doc doc-children">







<div class="doc doc-object doc-class">



<h4 id="services.tokenizer.core.base.AbstractTokenizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>AbstractTokenizer</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for all tokenizer implementations.</p>
<p>This class defines the core interface that all tokenizer plugins must implement.
It provides a clean contract for tokenization operations while allowing for
different implementation strategies.</p>












<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.base.AbstractTokenizer.__init__&lt;/code&gt;)" href="#services.tokenizer.core.base.AbstractTokenizer.__init__">__init__</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Initialize the tokenizer with configuration.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-abstractmethod&quot;&gt;&lt;code&gt;abstractmethod&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.base.AbstractTokenizer.tokenize&lt;/code&gt;)" href="#services.tokenizer.core.base.AbstractTokenizer.tokenize">tokenize</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Tokenize input text into a list of tokens.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>




<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-property&quot;&gt;&lt;code&gt;property&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.base.AbstractTokenizer.config&lt;/code&gt;)" href="#services.tokenizer.core.base.AbstractTokenizer.config">config</a></code></td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig">TokenizerConfig</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Get the current tokenizer configuration.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AbstractTokenizer</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base class for all tokenizer implementations.</span>

<span class="sd">    This class defines the core interface that all tokenizer plugins must implement.</span>
<span class="sd">    It provides a clean contract for tokenization operations while allowing for</span>
<span class="sd">    different implementation strategies.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TokenizerConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the tokenizer with configuration.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: Tokenizer configuration. If None, default config will be used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="n">config</span> <span class="ow">or</span> <span class="n">TokenizerConfig</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenizerConfig</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the current tokenizer configuration.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tokenize input text into a list of tokens.</span>

<span class="sd">        This is the main tokenization method that all implementations must provide.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Input text to tokenize</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of tokens extracted from the input text</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_preprocess_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply preprocessing to text before tokenization.</span>

<span class="sd">        This method applies configuration-based preprocessing such as</span>
<span class="sd">        case handling and Unicode normalization.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Input text to preprocess</span>

<span class="sd">        Returns:</span>
<span class="sd">            Preprocessed text</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">text</span>

        <span class="c1"># Apply Unicode normalization</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">normalize_unicode</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">unicodedata</span>

            <span class="n">text</span> <span class="o">=</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s2">&quot;NFKC&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

        <span class="c1"># Apply case handling</span>
        <span class="kn">from</span> <span class="nn">.types</span> <span class="kn">import</span> <span class="n">CaseHandling</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">case_handling</span> <span class="o">==</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">LOWERCASE</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">case_handling</span> <span class="o">==</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">UPPERCASE</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">case_handling</span> <span class="o">==</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">NORMALIZE</span><span class="p">:</span>
            <span class="c1"># TODO: Implement proper noun detection for smart normalization</span>
            <span class="c1"># Currently using simple lowercase as a placeholder</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">text</span>

    <span class="k">def</span> <span class="nf">_postprocess_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="n">TokenList</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply post-processing to extracted tokens.</span>

<span class="sd">        This method applies configuration-based filtering and cleanup</span>
<span class="sd">        to the token list.</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens: List of raw tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            Processed token list</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tokens</span>

        <span class="n">processed_tokens</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="c1"># Strip whitespace if configured</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">strip_whitespace</span><span class="p">:</span>
                <span class="n">token</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

            <span class="c1"># Skip empty tokens</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># Filter emojis if not included</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">include_emoji</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_emoji</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="c1"># Apply length filtering</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">min_token_length</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">max_token_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="o">.</span><span class="n">max_token_length</span>
            <span class="p">):</span>
                <span class="k">continue</span>

            <span class="n">processed_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">processed_tokens</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_emoji</span><span class="p">(</span><span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if a token is an emoji character.</span>

<span class="sd">        Args:</span>
<span class="sd">            token: Token to check</span>

<span class="sd">        Returns:</span>
<span class="sd">            True if the token is an emoji, False otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Accept sequences made of emoji code points plus common modifiers</span>
        <span class="n">EMOJI_RANGES</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="mh">0x1F600</span><span class="p">,</span> <span class="mh">0x1F64F</span><span class="p">),</span>  <span class="c1"># Emoticons</span>
            <span class="p">(</span><span class="mh">0x1F300</span><span class="p">,</span> <span class="mh">0x1F5FF</span><span class="p">),</span>  <span class="c1"># Misc Symbols &amp; Pictographs</span>
            <span class="p">(</span><span class="mh">0x1F680</span><span class="p">,</span> <span class="mh">0x1F6FF</span><span class="p">),</span>  <span class="c1"># Transport &amp; Map</span>
            <span class="p">(</span><span class="mh">0x1F1E6</span><span class="p">,</span> <span class="mh">0x1F1FF</span><span class="p">),</span>  <span class="c1"># Regional Indicators</span>
            <span class="p">(</span><span class="mh">0x2600</span><span class="p">,</span> <span class="mh">0x26FF</span><span class="p">),</span>  <span class="c1"># Misc symbols</span>
            <span class="p">(</span><span class="mh">0x2700</span><span class="p">,</span> <span class="mh">0x27BF</span><span class="p">),</span>  <span class="c1"># Dingbats</span>
            <span class="p">(</span><span class="mh">0x1F900</span><span class="p">,</span> <span class="mh">0x1F9FF</span><span class="p">),</span>  <span class="c1"># Supplemental Symbols &amp; Pictographs</span>
            <span class="p">(</span><span class="mh">0x1FA70</span><span class="p">,</span> <span class="mh">0x1FAFF</span><span class="p">),</span>  <span class="c1"># Symbols &amp; Pictographs Extended-A</span>
        <span class="p">)</span>
        <span class="n">MODIFIERS</span> <span class="o">=</span> <span class="p">{</span><span class="mh">0x200D</span><span class="p">,</span> <span class="mh">0xFE0E</span><span class="p">,</span> <span class="mh">0xFE0F</span><span class="p">}</span>  <span class="c1"># ZWJ, VS15, VS16</span>
        <span class="n">SKIN_TONE</span> <span class="o">=</span> <span class="p">(</span><span class="mh">0x1F3FB</span><span class="p">,</span> <span class="mh">0x1F3FF</span><span class="p">)</span>
        <span class="n">TAGS</span> <span class="o">=</span> <span class="p">(</span><span class="mh">0xE0020</span><span class="p">,</span> <span class="mh">0xE007F</span><span class="p">)</span>  <span class="c1"># Emoji tag sequences</span>

        <span class="k">def</span> <span class="nf">in_any_range</span><span class="p">(</span><span class="n">cp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">ranges</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">ranges</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">cp</span> <span class="o">&lt;=</span> <span class="n">b</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">def</span> <span class="nf">is_modifier</span><span class="p">(</span><span class="n">cp</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">cp</span> <span class="ow">in</span> <span class="n">MODIFIERS</span>
                <span class="ow">or</span> <span class="n">SKIN_TONE</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">cp</span> <span class="o">&lt;=</span> <span class="n">SKIN_TONE</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="ow">or</span> <span class="n">TAGS</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">cp</span> <span class="o">&lt;=</span> <span class="n">TAGS</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
            <span class="n">cp</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">in_any_range</span><span class="p">(</span><span class="n">cp</span><span class="p">,</span> <span class="n">EMOJI_RANGES</span><span class="p">)</span> <span class="ow">or</span> <span class="n">is_modifier</span><span class="p">(</span><span class="n">cp</span><span class="p">)):</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.core.base.AbstractTokenizer.__init__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Initialize the tokenizer with configuration.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h6 id="services.tokenizer.core.base.AbstractTokenizer.__init__(config)" class="doc doc-heading doc-heading-parameter">                  <code>config</code>
</h6>            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig">TokenizerConfig</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tokenizer configuration. If None, default config will be used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/core/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TokenizerConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize the tokenizer with configuration.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: Tokenizer configuration. If None, default config will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="n">config</span> <span class="ow">or</span> <span class="n">TokenizerConfig</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.base.AbstractTokenizer.config" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">config</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Get the current tokenizer configuration.</p>

    </div>

</div>






<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.core.base.AbstractTokenizer.tokenize" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Tokenize input text into a list of tokens.</p>
<p>This is the main tokenization method that all implementations must provide.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h6 id="services.tokenizer.core.base.AbstractTokenizer.tokenize(text)" class="doc doc-heading doc-heading-parameter">                  <code>text</code>
</h6>            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input text to tokenize</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="services.tokenizer.core.types.TokenList">TokenList</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of tokens extracted from the input text</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/core/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenize input text into a list of tokens.</span>

<span class="sd">    This is the main tokenization method that all implementations must provide.</span>

<span class="sd">    Args:</span>
<span class="sd">        text: Input text to tokenize</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of tokens extracted from the input text</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>








  </div>

    </div>

</div>






<div class="doc doc-object doc-module">



<h3 id="services.tokenizer.core.types" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <code>types</code>


</h3>

    <div class="doc doc-contents ">

        <p>TokenizerConfig, enums, and shared types</p>
<p>This module contains configuration models, enumerations,
and shared type definitions used across the tokenizer service.</p>










<p><span class="doc-section-title">Classes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;CaseHandling&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.CaseHandling&lt;/code&gt;)" href="#services.tokenizer.core.types.CaseHandling">CaseHandling</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>How to handle character case during tokenization.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;LanguageFamily&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.LanguageFamily&lt;/code&gt;)" href="#services.tokenizer.core.types.LanguageFamily">LanguageFamily</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Language families that affect tokenization strategies.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenType&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.TokenType&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenType">TokenType</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Types of tokens that can be extracted.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig">TokenizerConfig</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Configuration for tokenizer behavior.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>







<div class="doc doc-children">







<div class="doc doc-object doc-class">



<h4 id="services.tokenizer.core.types.CaseHandling" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>CaseHandling</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="enum.Enum">Enum</span></code></p>



        <p>How to handle character case during tokenization.</p>













              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CaseHandling</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;How to handle character case during tokenization.&quot;&quot;&quot;</span>

    <span class="n">PRESERVE</span> <span class="o">=</span> <span class="s2">&quot;preserve&quot;</span>  <span class="c1"># Keep original case</span>
    <span class="n">LOWERCASE</span> <span class="o">=</span> <span class="s2">&quot;lowercase&quot;</span>  <span class="c1"># Convert to lowercase</span>
    <span class="n">UPPERCASE</span> <span class="o">=</span> <span class="s2">&quot;uppercase&quot;</span>  <span class="c1"># Convert to uppercase</span>
    <span class="n">NORMALIZE</span> <span class="o">=</span> <span class="s2">&quot;normalize&quot;</span>  <span class="c1"># Smart case normalization</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">





  </div>

    </div>

</div>






<div class="doc doc-object doc-class">



<h4 id="services.tokenizer.core.types.LanguageFamily" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>LanguageFamily</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="str">str</span></code>, <code><span title="enum.Enum">Enum</span></code></p>



        <p>Language families that affect tokenization strategies.</p>













              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LanguageFamily</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Language families that affect tokenization strategies.&quot;&quot;&quot;</span>

    <span class="n">LATIN</span> <span class="o">=</span> <span class="s2">&quot;latin&quot;</span>  <span class="c1"># Space-separated languages (English, French, etc.)</span>
    <span class="n">CJK</span> <span class="o">=</span> <span class="s2">&quot;cjk&quot;</span>  <span class="c1"># Chinese, Japanese, Korean</span>
    <span class="n">ARABIC</span> <span class="o">=</span> <span class="s2">&quot;arabic&quot;</span>  <span class="c1"># Arabic script languages</span>
    <span class="n">MIXED</span> <span class="o">=</span> <span class="s2">&quot;mixed&quot;</span>  <span class="c1"># Mixed content requiring multiple strategies</span>
    <span class="n">UNKNOWN</span> <span class="o">=</span> <span class="s2">&quot;unknown&quot;</span>  <span class="c1"># Language detection failed or not performed</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">





  </div>

    </div>

</div>






<div class="doc doc-object doc-class">



<h4 id="services.tokenizer.core.types.TokenType" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>TokenType</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="str">str</span></code>, <code><span title="enum.Enum">Enum</span></code></p>



        <p>Types of tokens that can be extracted.</p>













              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TokenType</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Types of tokens that can be extracted.&quot;&quot;&quot;</span>

    <span class="n">WORD</span> <span class="o">=</span> <span class="s2">&quot;word&quot;</span>  <span class="c1"># Regular words</span>
    <span class="n">PUNCTUATION</span> <span class="o">=</span> <span class="s2">&quot;punctuation&quot;</span>  <span class="c1"># Punctuation marks</span>
    <span class="n">NUMERIC</span> <span class="o">=</span> <span class="s2">&quot;numeric&quot;</span>  <span class="c1"># Numbers</span>
    <span class="n">EMOJI</span> <span class="o">=</span> <span class="s2">&quot;emoji&quot;</span>  <span class="c1"># Emoji characters</span>
    <span class="n">HASHTAG</span> <span class="o">=</span> <span class="s2">&quot;hashtag&quot;</span>  <span class="c1"># Social media hashtags</span>
    <span class="n">MENTION</span> <span class="o">=</span> <span class="s2">&quot;mention&quot;</span>  <span class="c1"># Social media mentions</span>
    <span class="n">URL</span> <span class="o">=</span> <span class="s2">&quot;url&quot;</span>  <span class="c1"># URLs and links</span>
    <span class="n">EMAIL</span> <span class="o">=</span> <span class="s2">&quot;email&quot;</span>  <span class="c1"># Email addresses</span>
    <span class="n">WHITESPACE</span> <span class="o">=</span> <span class="s2">&quot;whitespace&quot;</span>  <span class="c1"># Whitespace (when preserved)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">





  </div>

    </div>

</div>






<div class="doc doc-object doc-class">



<h4 id="services.tokenizer.core.types.TokenizerConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>TokenizerConfig</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="pydantic.BaseModel">BaseModel</span></code></p>

        <p>Configuration for tokenizer behavior.</p>
<p>Controls all aspects of text tokenization including script handling,
social media entity processing, and output formatting.</p>
<p>Social Media Entity Behavior:
- extract_hashtags/extract_mentions: When False, splits into component words
- include_urls/include_emails: When False, completely excludes (no fragmentation)</p>

    

        <p>Fields:</p>
        <ul>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;fallback_language_family&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LanguageFamily&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MIXED&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.fallback_language_family&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.fallback_language_family">fallback_language_family</a></code>
                (<code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;LanguageFamily&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.LanguageFamily&lt;/code&gt;)" href="#services.tokenizer.core.types.LanguageFamily">LanguageFamily</a></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_punctuation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_punctuation&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_punctuation">include_punctuation</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_numeric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_numeric&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_numeric">include_numeric</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_emoji&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_emoji&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_emoji">include_emoji</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;case_handling&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CaseHandling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LOWERCASE&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.case_handling&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.case_handling">case_handling</a></code>
                (<code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;CaseHandling&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.CaseHandling&lt;/code&gt;)" href="#services.tokenizer.core.types.CaseHandling">CaseHandling</a></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;normalize_unicode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.normalize_unicode&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.normalize_unicode">normalize_unicode</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_hashtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_hashtags&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_hashtags">extract_hashtags</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_mentions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_mentions&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_mentions">extract_mentions</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_cashtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_cashtags&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_cashtags">extract_cashtags</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_urls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_urls&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_urls">include_urls</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_emails&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_emails&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_emails">include_emails</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;min_token_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.min_token_length&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.min_token_length">min_token_length</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;max_token_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.max_token_length&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.max_token_length">max_token_length</a></code>
                (<code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;strip_whitespace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.strip_whitespace&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.strip_whitespace">strip_whitespace</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
        </ul>


              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TokenizerConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for tokenizer behavior.</span>

<span class="sd">    Controls all aspects of text tokenization including script handling,</span>
<span class="sd">    social media entity processing, and output formatting.</span>

<span class="sd">    Social Media Entity Behavior:</span>
<span class="sd">    - extract_hashtags/extract_mentions: When False, splits into component words</span>
<span class="sd">    - include_urls/include_emails: When False, completely excludes (no fragmentation)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Language detection settings</span>
    <span class="n">fallback_language_family</span><span class="p">:</span> <span class="n">LanguageFamily</span> <span class="o">=</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Default language family when detection fails or mixed content is found.&quot;&quot;&quot;</span>

    <span class="c1"># Token type filtering</span>
    <span class="n">include_punctuation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include punctuation marks as separate tokens.&quot;&quot;&quot;</span>

    <span class="n">include_numeric</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include numeric tokens (integers, decimals, etc.).&quot;&quot;&quot;</span>

    <span class="n">include_emoji</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include emoji characters as tokens.&quot;&quot;&quot;</span>

    <span class="c1"># Text preprocessing</span>
    <span class="n">case_handling</span><span class="p">:</span> <span class="n">CaseHandling</span> <span class="o">=</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">LOWERCASE</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;How to handle character case during tokenization.&quot;&quot;&quot;</span>

    <span class="n">normalize_unicode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to apply Unicode NFKC normalization. Default False to preserve unicode tricks for bot detection.&quot;&quot;&quot;</span>

    <span class="c1"># Social media features</span>
    <span class="n">extract_hashtags</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve hashtags as single tokens. If False, splits into component words.&quot;&quot;&quot;</span>

    <span class="n">extract_mentions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve @mentions as single tokens. If False, splits into component words.&quot;&quot;&quot;</span>

    <span class="n">extract_cashtags</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve cashtags ($AAPL) as single tokens. If False, splits into components.&quot;&quot;&quot;</span>

    <span class="n">include_urls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include URLs as tokens. If False, URLs are completely excluded (not fragmented).&quot;&quot;&quot;</span>

    <span class="n">include_emails</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include email addresses as tokens. If False, emails are completely excluded (not fragmented).&quot;&quot;&quot;</span>

    <span class="c1"># Output formatting</span>
    <span class="n">min_token_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Minimum length for tokens to be included in output.&quot;&quot;&quot;</span>

    <span class="n">max_token_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Maximum length for tokens. If None, no length limit is applied.&quot;&quot;&quot;</span>

    <span class="n">strip_whitespace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to strip leading/trailing whitespace from tokens.&quot;&quot;&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>


<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.case_handling" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">case_handling</span> <span class="o">=</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">LOWERCASE</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>How to handle character case during tokenization.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.extract_cashtags" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_cashtags</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to preserve cashtags ($AAPL) as single tokens. If False, splits into components.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.extract_hashtags" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_hashtags</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to preserve hashtags as single tokens. If False, splits into component words.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.extract_mentions" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_mentions</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to preserve @mentions as single tokens. If False, splits into component words.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.fallback_language_family" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">fallback_language_family</span> <span class="o">=</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Default language family when detection fails or mixed content is found.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.include_emails" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_emails</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to include email addresses as tokens. If False, emails are completely excluded (not fragmented).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.include_emoji" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_emoji</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to include emoji characters as tokens.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.include_numeric" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_numeric</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to include numeric tokens (integers, decimals, etc.).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.include_punctuation" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_punctuation</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to include punctuation marks as separate tokens.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.include_urls" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_urls</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to include URLs as tokens. If False, URLs are completely excluded (not fragmented).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.max_token_length" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">max_token_length</span> <span class="o">=</span> <span class="kc">None</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Maximum length for tokens. If None, no length limit is applied.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.min_token_length" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">min_token_length</span> <span class="o">=</span> <span class="mi">1</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Minimum length for tokens to be included in output.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.normalize_unicode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">normalize_unicode</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to apply Unicode NFKC normalization. Default False to preserve unicode tricks for bot detection.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="services.tokenizer.core.types.TokenizerConfig.strip_whitespace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">strip_whitespace</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h5>


    <div class="doc doc-contents ">

        <p>Whether to strip leading/trailing whitespace from tokens.</p>

    </div>

</div>




  </div>

    </div>

</div>




  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="services.tokenizer.basic" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <code>services.tokenizer.basic</code>


</h2>

    <div class="doc doc-contents first">

        <p>Basic tokenizer implementation.</p>
<p>This module exports the BasicTokenizer implementation that provides
fundamental Unicode-aware tokenization capabilities for social media text.</p>






<p><span class="doc-section-title">Modules:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-module&quot;&gt;&lt;/code&gt;            &lt;code&gt;patterns&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns&lt;/code&gt;)" href="#services.tokenizer.basic.patterns">patterns</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Regex patterns for text tokenization.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-module&quot;&gt;&lt;/code&gt;            &lt;code&gt;tokenizer&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.tokenizer&lt;/code&gt;)" href="#services.tokenizer.basic.tokenizer">tokenizer</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>BasicTokenizer implementation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>






<p><span class="doc-section-title">Classes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;BasicTokenizer&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.BasicTokenizer&lt;/code&gt;)" href="#services.tokenizer.basic.BasicTokenizer">BasicTokenizer</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Unicode-aware basic tokenizer for social media text.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.basic.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.basic.TokenizerConfig">TokenizerConfig</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Configuration for tokenizer behavior.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>




<p><span class="doc-section-title">Functions:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-function&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;create_basic_tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.create_basic_tokenizer&lt;/code&gt;)" href="#services.tokenizer.basic.create_basic_tokenizer">create_basic_tokenizer</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Create a BasicTokenizer with optional configuration.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-function&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;get_patterns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.get_patterns&lt;/code&gt;)" href="#services.tokenizer.basic.get_patterns">get_patterns</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Get global TokenizerPatterns instance.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-function&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;tokenize_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.tokenize_text&lt;/code&gt;)" href="#services.tokenizer.basic.tokenize_text">tokenize_text</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Simple convenience function for basic text tokenization.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>





<div class="doc doc-children">







<div class="doc doc-object doc-class">



<h3 id="services.tokenizer.basic.BasicTokenizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>BasicTokenizer</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;AbstractTokenizer&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.base.AbstractTokenizer&lt;/code&gt;)" href="#services.tokenizer.core.base.AbstractTokenizer">AbstractTokenizer</a></code></p>



        <p>Unicode-aware basic tokenizer for social media text.</p>
<p>This tokenizer handles mixed-script content, preserves social media entities
(@mentions, #hashtags, URLs), and applies appropriate tokenization strategies
for different script families.</p>












<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.BasicTokenizer.__init__&lt;/code&gt;)" href="#services.tokenizer.basic.BasicTokenizer.__init__">__init__</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Initialize BasicTokenizer with configuration.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.BasicTokenizer.tokenize&lt;/code&gt;)" href="#services.tokenizer.basic.BasicTokenizer.tokenize">tokenize</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Tokenize input text into a list of tokens.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>



              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/basic/tokenizer.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BasicTokenizer</span><span class="p">(</span><span class="n">AbstractTokenizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unicode-aware basic tokenizer for social media text.</span>

<span class="sd">    This tokenizer handles mixed-script content, preserves social media entities</span>
<span class="sd">    (@mentions, #hashtags, URLs), and applies appropriate tokenization strategies</span>
<span class="sd">    for different script families.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TokenizerConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize BasicTokenizer with configuration.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: Tokenizer configuration. If None, default config will be used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span> <span class="o">=</span> <span class="n">get_patterns</span><span class="p">()</span>

        <span class="c1"># Compile regex pattern for character-level script detection (performance optimization)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_CHAR_LEVEL_PATTERN</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">&quot;[\u4e00-\u9fff&quot;</span>  <span class="c1"># CJK Unified Ideographs</span>
            <span class="sa">r</span><span class="s2">&quot;\u3400-\u4dbf&quot;</span>  <span class="c1"># CJK Extension A</span>
            <span class="sa">r</span><span class="s2">&quot;\u3040-\u309f&quot;</span>  <span class="c1"># Hiragana</span>
            <span class="sa">r</span><span class="s2">&quot;\u30a0-\u30ff&quot;</span>  <span class="c1"># Katakana</span>
            <span class="sa">r</span><span class="s2">&quot;\u0e00-\u0e7f&quot;</span>  <span class="c1"># Thai</span>
            <span class="sa">r</span><span class="s2">&quot;\u0e80-\u0eff&quot;</span>  <span class="c1"># Lao</span>
            <span class="sa">r</span><span class="s2">&quot;\u1000-\u109f&quot;</span>  <span class="c1"># Myanmar</span>
            <span class="sa">r</span><span class="s2">&quot;\u1780-\u17ff]&quot;</span>  <span class="c1"># Khmer</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tokenize input text into a list of tokens.</span>

<span class="sd">        Applies appropriate tokenization strategies for mixed-script content</span>
<span class="sd">        while preserving social media entities and handling Unicode correctly.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Input text to tokenize</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of tokens extracted from the input text in document order</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Apply preprocessing</span>
        <span class="n">processed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">processed_text</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Extract tokens using comprehensive regex pattern</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_tokens</span><span class="p">(</span><span class="n">processed_text</span><span class="p">)</span>

        <span class="c1"># Apply post-processing</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_postprocess_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_extract_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract tokens using comprehensive regex patterns.</span>
<span class="sd">        Preserves the original order of tokens as they appear in the input text.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Preprocessed text to tokenize</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of extracted tokens in their original order</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_tokens_ordered</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_char_level_script</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if character belongs to a character-level script.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_CHAR_LEVEL_PATTERN</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">char</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_get_char_script</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the script family for a character.</span>

<span class="sd">        Args:</span>
<span class="sd">            char: Character to analyze</span>

<span class="sd">        Returns:</span>
<span class="sd">            Script family name</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">code_point</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>

        <span class="c1"># Latin script</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="p">(</span><span class="mh">0x0041</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x007A</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="mh">0x00C0</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x024F</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="mh">0x1E00</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x1EFF</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;latin&quot;</span>

        <span class="c1"># Korean Hangul (space-separated, NOT character-level!)</span>
        <span class="k">elif</span> <span class="mh">0xAC00</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0xD7AF</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;korean&quot;</span>

        <span class="c1"># Character-level scripts (CJK, Thai, etc.)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">char</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;cjk&quot;</span>

        <span class="c1"># Arabic script</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="p">(</span><span class="mh">0x0600</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x06FF</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="mh">0x0750</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x077F</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="mh">0x08A0</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x08FF</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;arabic&quot;</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;other&quot;</span>

    <span class="k">def</span> <span class="nf">_extract_tokens_ordered</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">language_family</span><span class="p">:</span> <span class="n">LanguageFamily</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract tokens preserving their original order in the text.</span>

<span class="sd">        Uses a single comprehensive regex pattern to find ALL tokens in document order,</span>
<span class="sd">        eliminating the need for complex segmentation and reassembly logic.</span>
<span class="sd">        This is the Phase 2 optimization that removes O(n×segments) complexity.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Preprocessed text to tokenize</span>
<span class="sd">            language_family: Detected language family for the full text</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of extracted tokens in their original order</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Remove excluded entities (URLs/emails) from text if they are disabled</span>
        <span class="c1"># This prevents them from being tokenized into component words</span>
        <span class="n">exclusion_pattern</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="o">.</span><span class="n">get_exclusion_pattern</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exclusion_pattern</span><span class="p">:</span>
            <span class="c1"># Replace excluded entities with spaces to maintain word boundaries</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">exclusion_pattern</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
            <span class="c1"># Clean up multiple spaces</span>
            <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Get comprehensive pattern based on configuration</span>
        <span class="c1"># This single pattern finds ALL tokens in document order</span>
        <span class="n">comprehensive_pattern</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="o">.</span><span class="n">get_comprehensive_pattern</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="p">)</span>

        <span class="c1"># Single regex call gets all tokens in order - this is the key optimization!</span>
        <span class="n">raw_tokens</span> <span class="o">=</span> <span class="n">comprehensive_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="c1"># If no tokens were found but input has content, use fallback for edge cases</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">raw_tokens</span> <span class="ow">and</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="c1"># For pure punctuation or unrecognized content, return as single token</span>
            <span class="c1"># This maintains compatibility with old tokenizer behavior for edge cases</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>

        <span class="c1"># Apply postprocessing for language-specific behavior and configuration filtering</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">raw_tokens</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                <span class="k">continue</span>

            <span class="c1"># Clean URLs by removing trailing punctuation</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_url_like</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
                <span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_clean_url_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

            <span class="c1"># For character-level scripts, break down multi-character tokens into individual characters</span>
            <span class="c1"># This maintains compatibility with existing test expectations</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">language_family</span> <span class="o">==</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">CJK</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_contains_char_level_chars</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># Only break down pure character-level tokens, not mixed tokens</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_pure_char_level_token</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
                    <span class="n">tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">token</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Mixed token - keep as is but process character-level parts</span>
                    <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">language_family</span> <span class="o">==</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span><span class="p">:</span>
                <span class="c1"># For mixed script, break down character-level script parts but keep Latin parts whole</span>
                <span class="n">processed_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_mixed_script_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
                <span class="n">tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">processed_tokens</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">_is_punctuation_only</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token contains only punctuation.&quot;&quot;&quot;</span>
        <span class="n">punctuation_chars</span> <span class="o">=</span> <span class="s2">&quot;.!?;:,()[]</span><span class="si">{}</span><span class="se">\&quot;</span><span class="s2">&#39;-~`@#$%^&amp;*+=&lt;&gt;/|</span><span class="se">\\</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">c</span> <span class="ow">in</span> <span class="n">punctuation_chars</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_numeric_only</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token is purely numeric.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">token</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;%&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;$&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">isdigit</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_url_like</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token looks like a URL.&quot;&quot;&quot;</span>
        <span class="c1"># Don&#39;t classify emails as URLs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_email_like</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Explicit URL indicators (http://, https://, www., or protocol markers)</span>
        <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;http://&quot;</span><span class="p">,</span> <span class="s2">&quot;https://&quot;</span><span class="p">,</span> <span class="s2">&quot;www.&quot;</span><span class="p">))</span> <span class="ow">or</span> <span class="s2">&quot;://&quot;</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># Domain-like patterns (e.g., &quot;example.com&quot;)</span>
        <span class="c1"># But NOT abbreviations (e.g., &quot;U.S.&quot;, &quot;c.e.o.s&quot;)</span>
        <span class="c1"># Heuristic: URLs have at least one period NOT followed by a single uppercase/lowercase letter</span>
        <span class="c1"># This allows &quot;example.com&quot; but excludes &quot;U.S.&quot; and &quot;c.e.o.s&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">token</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>
            <span class="ow">and</span> <span class="s2">&quot;@&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">token</span>
        <span class="p">):</span>
            <span class="c1"># Check if this looks like an abbreviation (single letters between periods)</span>
            <span class="c1"># Pattern: letter(s).letter(s).letter(s) where segments are 1-3 chars</span>
            <span class="n">abbreviation_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;^[a-z]{1,3}(?:\.[a-z]{1,3})+\.?$&quot;</span>

            <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">abbreviation_pattern</span><span class="p">,</span> <span class="n">token</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># This is an abbreviation, not a URL</span>
            <span class="c1"># If it has a period and looks like a domain, it&#39;s URL-like</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_is_email_like</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token looks like an email address.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;@&quot;</span> <span class="ow">in</span> <span class="n">token</span> <span class="ow">and</span> <span class="s2">&quot;.&quot;</span> <span class="ow">in</span> <span class="n">token</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">token</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;@&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_clean_url_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url_token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove trailing punctuation from URL tokens.&quot;&quot;&quot;</span>
        <span class="n">trailing_punctuation</span> <span class="o">=</span> <span class="s2">&quot;.!?;:,)]}</span><span class="se">\&quot;</span><span class="s2">&#39;&quot;</span>
        <span class="k">return</span> <span class="n">url_token</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="n">trailing_punctuation</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_contains_char_level_chars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token contains any character-level script characters.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_pure_char_level_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token contains only character-level script characters.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="ow">or</span> <span class="n">char</span><span class="o">.</span><span class="n">isspace</span><span class="p">()</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_process_mixed_script_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process mixed script tokens by breaking down character-level script parts.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_contains_char_level_chars</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">token</span><span class="p">]</span>

        <span class="c1"># Check if token mixes Latin with CJK</span>
        <span class="n">has_latin</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">isascii</span><span class="p">()</span> <span class="ow">and</span> <span class="n">c</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>
        <span class="n">has_cjk</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>

        <span class="c1"># Don&#39;t apply mixed-script preservation to social media entities</span>
        <span class="n">is_social_entity</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;@&quot;</span><span class="p">,</span> <span class="s2">&quot;#&quot;</span><span class="p">,</span> <span class="s2">&quot;$&quot;</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">has_latin</span> <span class="ow">and</span> <span class="n">has_cjk</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_social_entity</span><span class="p">:</span>
            <span class="c1"># Mixed script - keep intact (brand names, bot tricks)</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">token</span><span class="p">]</span>

        <span class="c1"># Rest of existing logic for pure CJK tokens...</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_token</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">current_is_cjk</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
            <span class="n">char_is_cjk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">current_is_cjk</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">current_is_cjk</span> <span class="o">=</span> <span class="n">char_is_cjk</span>
                <span class="n">current_token</span> <span class="o">=</span> <span class="n">char</span>
            <span class="k">elif</span> <span class="n">char_is_cjk</span> <span class="o">==</span> <span class="n">current_is_cjk</span><span class="p">:</span>
                <span class="n">current_token</span> <span class="o">+=</span> <span class="n">char</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Script change</span>
                <span class="k">if</span> <span class="n">current_token</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">current_is_cjk</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Break CJK into individual characters</span>
                        <span class="n">result</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">current_token</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span>
                <span class="n">current_token</span> <span class="o">=</span> <span class="n">char</span>
                <span class="n">current_is_cjk</span> <span class="o">=</span> <span class="n">char_is_cjk</span>

        <span class="c1"># Handle final token</span>
        <span class="k">if</span> <span class="n">current_token</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">current_is_cjk</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">current_token</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">_postprocess_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="n">TokenList</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply post-processing to extracted tokens.</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens: List of raw tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            Processed token list</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tokens</span>

        <span class="c1"># Apply base class post-processing (length filtering, whitespace stripping, etc.)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_postprocess_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-function">


<h4 id="services.tokenizer.basic.BasicTokenizer.__init__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initialize BasicTokenizer with configuration.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h5 id="services.tokenizer.basic.BasicTokenizer.__init__(config)" class="doc doc-heading doc-heading-parameter">                  <code>config</code>
</h5>            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig">TokenizerConfig</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tokenizer configuration. If None, default config will be used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/tokenizer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TokenizerConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize BasicTokenizer with configuration.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: Tokenizer configuration. If None, default config will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span> <span class="o">=</span> <span class="n">get_patterns</span><span class="p">()</span>

    <span class="c1"># Compile regex pattern for character-level script detection (performance optimization)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_CHAR_LEVEL_PATTERN</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="sa">r</span><span class="s2">&quot;[\u4e00-\u9fff&quot;</span>  <span class="c1"># CJK Unified Ideographs</span>
        <span class="sa">r</span><span class="s2">&quot;\u3400-\u4dbf&quot;</span>  <span class="c1"># CJK Extension A</span>
        <span class="sa">r</span><span class="s2">&quot;\u3040-\u309f&quot;</span>  <span class="c1"># Hiragana</span>
        <span class="sa">r</span><span class="s2">&quot;\u30a0-\u30ff&quot;</span>  <span class="c1"># Katakana</span>
        <span class="sa">r</span><span class="s2">&quot;\u0e00-\u0e7f&quot;</span>  <span class="c1"># Thai</span>
        <span class="sa">r</span><span class="s2">&quot;\u0e80-\u0eff&quot;</span>  <span class="c1"># Lao</span>
        <span class="sa">r</span><span class="s2">&quot;\u1000-\u109f&quot;</span>  <span class="c1"># Myanmar</span>
        <span class="sa">r</span><span class="s2">&quot;\u1780-\u17ff]&quot;</span>  <span class="c1"># Khmer</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="services.tokenizer.basic.BasicTokenizer.tokenize" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Tokenize input text into a list of tokens.</p>
<p>Applies appropriate tokenization strategies for mixed-script content
while preserving social media entities and handling Unicode correctly.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h5 id="services.tokenizer.basic.BasicTokenizer.tokenize(text)" class="doc doc-heading doc-heading-parameter">                  <code>text</code>
</h5>            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input text to tokenize</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="services.tokenizer.core.types.TokenList">TokenList</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of tokens extracted from the input text in document order</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/tokenizer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenize input text into a list of tokens.</span>

<span class="sd">    Applies appropriate tokenization strategies for mixed-script content</span>
<span class="sd">    while preserving social media entities and handling Unicode correctly.</span>

<span class="sd">    Args:</span>
<span class="sd">        text: Input text to tokenize</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of tokens extracted from the input text in document order</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="c1"># Apply preprocessing</span>
    <span class="n">processed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">processed_text</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="c1"># Extract tokens using comprehensive regex pattern</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_tokens</span><span class="p">(</span><span class="n">processed_text</span><span class="p">)</span>

    <span class="c1"># Apply post-processing</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_postprocess_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>






<div class="doc doc-object doc-class">



<h3 id="services.tokenizer.basic.TokenizerConfig" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>TokenizerConfig</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-model"><code>pydantic-model</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="pydantic.BaseModel">BaseModel</span></code></p>

        <p>Configuration for tokenizer behavior.</p>
<p>Controls all aspects of text tokenization including script handling,
social media entity processing, and output formatting.</p>
<p>Social Media Entity Behavior:
- extract_hashtags/extract_mentions: When False, splits into component words
- include_urls/include_emails: When False, completely excludes (no fragmentation)</p>

    

        <p>Fields:</p>
        <ul>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;fallback_language_family&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LanguageFamily&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MIXED&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.fallback_language_family&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.fallback_language_family">fallback_language_family</a></code>
                (<code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;LanguageFamily&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.LanguageFamily&lt;/code&gt;)" href="#services.tokenizer.core.types.LanguageFamily">LanguageFamily</a></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_punctuation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_punctuation&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_punctuation">include_punctuation</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_numeric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_numeric&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_numeric">include_numeric</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_emoji&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_emoji&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_emoji">include_emoji</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;case_handling&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CaseHandling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LOWERCASE&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.case_handling&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.case_handling">case_handling</a></code>
                (<code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;CaseHandling&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.types.CaseHandling&lt;/code&gt;)" href="#services.tokenizer.core.types.CaseHandling">CaseHandling</a></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;normalize_unicode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.normalize_unicode&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.normalize_unicode">normalize_unicode</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_hashtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_hashtags&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_hashtags">extract_hashtags</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_mentions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_mentions&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_mentions">extract_mentions</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;extract_cashtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.extract_cashtags&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.extract_cashtags">extract_cashtags</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_urls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_urls&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_urls">include_urls</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;include_emails&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.include_emails&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.include_emails">include_emails</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;min_token_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.min_token_length&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.min_token_length">min_token_length</a></code>
                (<code><span title="int">int</span></code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;max_token_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.max_token_length&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.max_token_length">max_token_length</a></code>
                (<code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>)
            </li>
            <li>
              <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;strip_whitespace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-field&quot;&gt;&lt;code&gt;pydantic-field&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig.strip_whitespace&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig.strip_whitespace">strip_whitespace</a></code>
                (<code><span title="bool">bool</span></code>)
            </li>
        </ul>


              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/core/types.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TokenizerConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for tokenizer behavior.</span>

<span class="sd">    Controls all aspects of text tokenization including script handling,</span>
<span class="sd">    social media entity processing, and output formatting.</span>

<span class="sd">    Social Media Entity Behavior:</span>
<span class="sd">    - extract_hashtags/extract_mentions: When False, splits into component words</span>
<span class="sd">    - include_urls/include_emails: When False, completely excludes (no fragmentation)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Language detection settings</span>
    <span class="n">fallback_language_family</span><span class="p">:</span> <span class="n">LanguageFamily</span> <span class="o">=</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Default language family when detection fails or mixed content is found.&quot;&quot;&quot;</span>

    <span class="c1"># Token type filtering</span>
    <span class="n">include_punctuation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include punctuation marks as separate tokens.&quot;&quot;&quot;</span>

    <span class="n">include_numeric</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include numeric tokens (integers, decimals, etc.).&quot;&quot;&quot;</span>

    <span class="n">include_emoji</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include emoji characters as tokens.&quot;&quot;&quot;</span>

    <span class="c1"># Text preprocessing</span>
    <span class="n">case_handling</span><span class="p">:</span> <span class="n">CaseHandling</span> <span class="o">=</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">LOWERCASE</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;How to handle character case during tokenization.&quot;&quot;&quot;</span>

    <span class="n">normalize_unicode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to apply Unicode NFKC normalization. Default False to preserve unicode tricks for bot detection.&quot;&quot;&quot;</span>

    <span class="c1"># Social media features</span>
    <span class="n">extract_hashtags</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve hashtags as single tokens. If False, splits into component words.&quot;&quot;&quot;</span>

    <span class="n">extract_mentions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve @mentions as single tokens. If False, splits into component words.&quot;&quot;&quot;</span>

    <span class="n">extract_cashtags</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to preserve cashtags ($AAPL) as single tokens. If False, splits into components.&quot;&quot;&quot;</span>

    <span class="n">include_urls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include URLs as tokens. If False, URLs are completely excluded (not fragmented).&quot;&quot;&quot;</span>

    <span class="n">include_emails</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to include email addresses as tokens. If False, emails are completely excluded (not fragmented).&quot;&quot;&quot;</span>

    <span class="c1"># Output formatting</span>
    <span class="n">min_token_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Minimum length for tokens to be included in output.&quot;&quot;&quot;</span>

    <span class="n">max_token_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Maximum length for tokens. If None, no length limit is applied.&quot;&quot;&quot;</span>

    <span class="n">strip_whitespace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Whether to strip leading/trailing whitespace from tokens.&quot;&quot;&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>


<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.case_handling" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">case_handling</span> <span class="o">=</span> <span class="n">CaseHandling</span><span class="o">.</span><span class="n">LOWERCASE</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>How to handle character case during tokenization.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.extract_cashtags" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_cashtags</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to preserve cashtags ($AAPL) as single tokens. If False, splits into components.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.extract_hashtags" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_hashtags</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to preserve hashtags as single tokens. If False, splits into component words.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.extract_mentions" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">extract_mentions</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to preserve @mentions as single tokens. If False, splits into component words.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.fallback_language_family" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">fallback_language_family</span> <span class="o">=</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Default language family when detection fails or mixed content is found.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.include_emails" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_emails</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include email addresses as tokens. If False, emails are completely excluded (not fragmented).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.include_emoji" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_emoji</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include emoji characters as tokens.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.include_numeric" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_numeric</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include numeric tokens (integers, decimals, etc.).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.include_punctuation" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_punctuation</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include punctuation marks as separate tokens.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.include_urls" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">include_urls</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to include URLs as tokens. If False, URLs are completely excluded (not fragmented).</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.max_token_length" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">max_token_length</span> <span class="o">=</span> <span class="kc">None</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Maximum length for tokens. If None, no length limit is applied.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.min_token_length" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">min_token_length</span> <span class="o">=</span> <span class="mi">1</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Minimum length for tokens to be included in output.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.normalize_unicode" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">normalize_unicode</span> <span class="o">=</span> <span class="kc">False</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to apply Unicode NFKC normalization. Default False to preserve unicode tricks for bot detection.</p>

    </div>

</div>






<div class="doc doc-object doc-attribute">



<h4 id="services.tokenizer.basic.TokenizerConfig.strip_whitespace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">strip_whitespace</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-pydantic-field"><code>pydantic-field</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to strip leading/trailing whitespace from tokens.</p>

    </div>

</div>




  </div>

    </div>

</div>






<div class="doc doc-object doc-function">


<h3 id="services.tokenizer.basic.create_basic_tokenizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">create_basic_tokenizer</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Create a BasicTokenizer with optional configuration.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/__init__.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_basic_tokenizer</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">TokenizerConfig</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BasicTokenizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a BasicTokenizer with optional configuration.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">TokenizerConfig</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">BasicTokenizer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h3 id="services.tokenizer.basic.get_patterns" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">get_patterns</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Get global TokenizerPatterns instance.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerPatterns&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.TokenizerPatterns&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.TokenizerPatterns">TokenizerPatterns</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Singleton TokenizerPatterns instance</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/patterns.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_patterns</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">TokenizerPatterns</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get global TokenizerPatterns instance.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Singleton TokenizerPatterns instance</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">_global_patterns</span>
    <span class="k">if</span> <span class="n">_global_patterns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_global_patterns</span> <span class="o">=</span> <span class="n">TokenizerPatterns</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">_global_patterns</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-module">



<h3 id="services.tokenizer.basic.patterns" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <code>patterns</code>


</h3>

    <div class="doc doc-contents ">

        <p>Regex patterns for text tokenization.</p>
<p>This module contains compiled regular expressions for extracting different
types of tokens from social media text, with fallback support for both
regex and re modules.</p>










<p><span class="doc-section-title">Classes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerPatterns&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.TokenizerPatterns&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.TokenizerPatterns">TokenizerPatterns</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Compiled regex patterns for tokenization.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>




<p><span class="doc-section-title">Functions:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-function&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;get_patterns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.get_patterns&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.get_patterns">get_patterns</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Get global TokenizerPatterns instance.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>





<div class="doc doc-children">







<div class="doc doc-object doc-class">



<h4 id="services.tokenizer.basic.patterns.TokenizerPatterns" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>TokenizerPatterns</code>


</h4>


    <div class="doc doc-contents ">



        <p>Compiled regex patterns for tokenization.</p>
<p>Organizes patterns logically and provides efficient compiled regex objects
for different token types found in social media text.</p>












<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.TokenizerPatterns.__init__&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.TokenizerPatterns.__init__">__init__</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Initialize and compile all tokenization patterns.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;get_comprehensive_pattern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.TokenizerPatterns.get_comprehensive_pattern&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_comprehensive_pattern">get_comprehensive_pattern</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Build comprehensive tokenization pattern based on configuration.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;get_exclusion_pattern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.TokenizerPatterns.get_exclusion_pattern&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_exclusion_pattern">get_exclusion_pattern</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Build pattern to identify and skip excluded entities in text.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;get_pattern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.TokenizerPatterns.get_pattern&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.TokenizerPatterns.get_pattern">get_pattern</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Get compiled pattern by name.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;list_patterns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.TokenizerPatterns.list_patterns&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.TokenizerPatterns.list_patterns">list_patterns</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Get list of available pattern names.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>



              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/basic/patterns.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TokenizerPatterns</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compiled regex patterns for tokenization.</span>

<span class="sd">    Organizes patterns logically and provides efficient compiled regex objects</span>
<span class="sd">    for different token types found in social media text.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize and compile all tokenization patterns.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compile_patterns</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pattern_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get compiled pattern by name.</span>

<span class="sd">        Args:</span>
<span class="sd">            pattern_name: Name of the pattern to retrieve</span>

<span class="sd">        Returns:</span>
<span class="sd">            Compiled regex pattern</span>

<span class="sd">        Raises:</span>
<span class="sd">            KeyError: If pattern name is not found</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">pattern_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pattern &#39;</span><span class="si">{</span><span class="n">pattern_name</span><span class="si">}</span><span class="s2">&#39; not found&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">[</span><span class="n">pattern_name</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_comprehensive_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build comprehensive tokenization pattern based on configuration.</span>

<span class="sd">        This creates a single regex pattern that finds ALL tokens in document order,</span>
<span class="sd">        eliminating the need for segmentation and reassembly. URLs and emails are</span>
<span class="sd">        conditionally included in the regex itself based on configuration, avoiding</span>
<span class="sd">        the need for post-processing filtering.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: TokenizerConfig specifying which token types to include</span>

<span class="sd">        Returns:</span>
<span class="sd">            Compiled regex pattern that matches all desired token types in priority order</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check cache first</span>
        <span class="n">cache_key</span> <span class="o">=</span> <span class="nb">hash</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
        <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="n">_comprehensive_pattern_cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_comprehensive_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>

        <span class="n">pattern_parts</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Conditionally add URL and email patterns based on configuration</span>
        <span class="c1"># This eliminates the need for post-processing filtering</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_urls</span><span class="p">:</span>
            <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_emails</span><span class="p">:</span>
            <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">extract_mentions</span><span class="p">:</span>
            <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;mention&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">extract_hashtags</span><span class="p">:</span>
            <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;hashtag&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="c1"># Cashtag pattern BEFORE numeric pattern (priority matters)</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">extract_cashtags</span><span class="p">:</span>
            <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;cashtag&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_emoji</span><span class="p">:</span>
            <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;emoji&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_numeric</span><span class="p">:</span>
            <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;numeric&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="c1"># Always include word pattern (this is the core tokenization)</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;word&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_punctuation</span><span class="p">:</span>
            <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;punctuation&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="c1"># Don&#39;t add the greedy fallback - let configuration control what gets captured</span>

        <span class="c1"># Combine patterns with alternation (| operator)</span>
        <span class="n">comprehensive_pattern</span> <span class="o">=</span> <span class="s2">&quot;(?:&quot;</span> <span class="o">+</span> <span class="s2">&quot;|&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pattern_parts</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">compiled_pattern</span> <span class="o">=</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                <span class="n">comprehensive_pattern</span><span class="p">,</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">IGNORECASE</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># Fallback to standard re module</span>
            <span class="k">if</span> <span class="n">REGEX_AVAILABLE</span> <span class="ow">and</span> <span class="n">REGEX_MODULE</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">re</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">compiled_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">comprehensive_pattern</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="c1"># Ultimate fallback - just match words</span>
                    <span class="n">compiled_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\S+&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">compiled_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\S+&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>

        <span class="c1"># Store in cache</span>
        <span class="n">_comprehensive_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">compiled_pattern</span>
        <span class="k">return</span> <span class="n">compiled_pattern</span>

    <span class="k">def</span> <span class="nf">get_exclusion_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build pattern to identify and skip excluded entities in text.</span>

<span class="sd">        This creates a pattern that matches URLs and emails that should be excluded,</span>
<span class="sd">        allowing the tokenizer to skip over them entirely instead of breaking them</span>
<span class="sd">        into component words.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: TokenizerConfig specifying which token types to exclude</span>

<span class="sd">        Returns:</span>
<span class="sd">            Compiled regex pattern that matches excluded entities, or None if no exclusions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check cache first</span>
        <span class="n">cache_key</span> <span class="o">=</span> <span class="nb">hash</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
        <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="n">_exclusion_pattern_cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_exclusion_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>

        <span class="n">exclusion_parts</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">include_urls</span><span class="p">:</span>
            <span class="n">exclusion_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">include_emails</span><span class="p">:</span>
            <span class="n">exclusion_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">include_numeric</span><span class="p">:</span>
            <span class="n">exclusion_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;numeric&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">exclusion_parts</span><span class="p">:</span>
            <span class="c1"># Cache None result</span>
            <span class="n">_exclusion_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># Combine exclusion patterns</span>
        <span class="n">exclusion_pattern</span> <span class="o">=</span> <span class="s2">&quot;(?:&quot;</span> <span class="o">+</span> <span class="s2">&quot;|&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">exclusion_parts</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">exclusion_pattern</span><span class="p">,</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># Fallback to standard re module</span>
            <span class="k">if</span> <span class="n">REGEX_AVAILABLE</span> <span class="ow">and</span> <span class="n">REGEX_MODULE</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">re</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">exclusion_pattern</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Store in cache</span>
        <span class="n">_exclusion_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">list_patterns</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get list of available pattern names.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_compile_patterns</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compile all regex patterns with fallback support.&quot;&quot;&quot;</span>

        <span class="c1"># Compile patterns with fallback handling</span>
        <span class="n">patterns_to_compile</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="n">URL_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;email&quot;</span><span class="p">:</span> <span class="n">EMAIL_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;mention&quot;</span><span class="p">:</span> <span class="n">MENTION_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;hashtag&quot;</span><span class="p">:</span> <span class="n">HASHTAG_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;cashtag&quot;</span><span class="p">:</span> <span class="n">CASHTAG_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;emoji&quot;</span><span class="p">:</span> <span class="n">EMOJI_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;numeric&quot;</span><span class="p">:</span> <span class="n">NUMERIC_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;word&quot;</span><span class="p">:</span> <span class="n">WORD_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;latin_word&quot;</span><span class="p">:</span> <span class="n">LATIN_WORD_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;cjk_chars&quot;</span><span class="p">:</span> <span class="n">CJK_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;arabic_chars&quot;</span><span class="p">:</span> <span class="n">ARABIC_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;punctuation&quot;</span><span class="p">:</span> <span class="n">PUNCTUATION_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;social_media&quot;</span><span class="p">:</span> <span class="n">SOCIAL_MEDIA_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;word_boundary&quot;</span><span class="p">:</span> <span class="n">WORD_BOUNDARY_PATTERN</span><span class="p">,</span>
            <span class="s2">&quot;combined_social_entities&quot;</span><span class="p">:</span> <span class="n">COMBINED_SOCIAL_ENTITIES_PATTERN</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">pattern</span> <span class="ow">in</span> <span class="n">patterns_to_compile</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                    <span class="n">pattern</span><span class="p">,</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">IGNORECASE</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="c1"># If compilation fails with regex module, fall back to re</span>
                <span class="k">if</span> <span class="n">REGEX_AVAILABLE</span> <span class="ow">and</span> <span class="n">REGEX_MODULE</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">re</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                        <span class="c1"># If both fail, create a simple fallback</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\S+&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Already using re module, create simple fallback</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\S+&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.basic.patterns.TokenizerPatterns.__init__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">()</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Initialize and compile all tokenization patterns.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/patterns.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize and compile all tokenization patterns.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compile_patterns</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.basic.patterns.TokenizerPatterns.get_comprehensive_pattern" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">get_comprehensive_pattern</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Build comprehensive tokenization pattern based on configuration.</p>
<p>This creates a single regex pattern that finds ALL tokens in document order,
eliminating the need for segmentation and reassembly. URLs and emails are
conditionally included in the regex itself based on configuration, avoiding
the need for post-processing filtering.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h6 id="services.tokenizer.basic.patterns.TokenizerPatterns.get_comprehensive_pattern(config)" class="doc doc-heading doc-heading-parameter">                  <code>config</code>
</h6>            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>TokenizerConfig specifying which token types to include</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Compiled regex pattern that matches all desired token types in priority order</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/patterns.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_comprehensive_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build comprehensive tokenization pattern based on configuration.</span>

<span class="sd">    This creates a single regex pattern that finds ALL tokens in document order,</span>
<span class="sd">    eliminating the need for segmentation and reassembly. URLs and emails are</span>
<span class="sd">    conditionally included in the regex itself based on configuration, avoiding</span>
<span class="sd">    the need for post-processing filtering.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: TokenizerConfig specifying which token types to include</span>

<span class="sd">    Returns:</span>
<span class="sd">        Compiled regex pattern that matches all desired token types in priority order</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check cache first</span>
    <span class="n">cache_key</span> <span class="o">=</span> <span class="nb">hash</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
    <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="n">_comprehensive_pattern_cache</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_comprehensive_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>

    <span class="n">pattern_parts</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Conditionally add URL and email patterns based on configuration</span>
    <span class="c1"># This eliminates the need for post-processing filtering</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_urls</span><span class="p">:</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_emails</span><span class="p">:</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">extract_mentions</span><span class="p">:</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;mention&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">extract_hashtags</span><span class="p">:</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;hashtag&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="c1"># Cashtag pattern BEFORE numeric pattern (priority matters)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">extract_cashtags</span><span class="p">:</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;cashtag&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_emoji</span><span class="p">:</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;emoji&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_numeric</span><span class="p">:</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;numeric&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="c1"># Always include word pattern (this is the core tokenization)</span>
    <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;word&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">include_punctuation</span><span class="p">:</span>
        <span class="n">pattern_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;punctuation&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="c1"># Don&#39;t add the greedy fallback - let configuration control what gets captured</span>

    <span class="c1"># Combine patterns with alternation (| operator)</span>
    <span class="n">comprehensive_pattern</span> <span class="o">=</span> <span class="s2">&quot;(?:&quot;</span> <span class="o">+</span> <span class="s2">&quot;|&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pattern_parts</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">compiled_pattern</span> <span class="o">=</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="n">comprehensive_pattern</span><span class="p">,</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">IGNORECASE</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="c1"># Fallback to standard re module</span>
        <span class="k">if</span> <span class="n">REGEX_AVAILABLE</span> <span class="ow">and</span> <span class="n">REGEX_MODULE</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">re</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">compiled_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">comprehensive_pattern</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="c1"># Ultimate fallback - just match words</span>
                <span class="n">compiled_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\S+&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">compiled_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\S+&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>

    <span class="c1"># Store in cache</span>
    <span class="n">_comprehensive_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">compiled_pattern</span>
    <span class="k">return</span> <span class="n">compiled_pattern</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.basic.patterns.TokenizerPatterns.get_exclusion_pattern" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">get_exclusion_pattern</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Build pattern to identify and skip excluded entities in text.</p>
<p>This creates a pattern that matches URLs and emails that should be excluded,
allowing the tokenizer to skip over them entirely instead of breaking them
into component words.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h6 id="services.tokenizer.basic.patterns.TokenizerPatterns.get_exclusion_pattern(config)" class="doc doc-heading doc-heading-parameter">                  <code>config</code>
</h6>            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>TokenizerConfig specifying which token types to exclude</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Compiled regex pattern that matches excluded entities, or None if no exclusions</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/patterns.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_exclusion_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build pattern to identify and skip excluded entities in text.</span>

<span class="sd">    This creates a pattern that matches URLs and emails that should be excluded,</span>
<span class="sd">    allowing the tokenizer to skip over them entirely instead of breaking them</span>
<span class="sd">    into component words.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: TokenizerConfig specifying which token types to exclude</span>

<span class="sd">    Returns:</span>
<span class="sd">        Compiled regex pattern that matches excluded entities, or None if no exclusions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check cache first</span>
    <span class="n">cache_key</span> <span class="o">=</span> <span class="nb">hash</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">model_dump</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
    <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="n">_exclusion_pattern_cache</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_exclusion_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>

    <span class="n">exclusion_parts</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">include_urls</span><span class="p">:</span>
        <span class="n">exclusion_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">include_emails</span><span class="p">:</span>
        <span class="n">exclusion_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;email&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">include_numeric</span><span class="p">:</span>
        <span class="n">exclusion_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pattern</span><span class="p">(</span><span class="s2">&quot;numeric&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">exclusion_parts</span><span class="p">:</span>
        <span class="c1"># Cache None result</span>
        <span class="n">_exclusion_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># Combine exclusion patterns</span>
    <span class="n">exclusion_pattern</span> <span class="o">=</span> <span class="s2">&quot;(?:&quot;</span> <span class="o">+</span> <span class="s2">&quot;|&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">exclusion_parts</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">exclusion_pattern</span><span class="p">,</span> <span class="n">REGEX_MODULE</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="c1"># Fallback to standard re module</span>
        <span class="k">if</span> <span class="n">REGEX_AVAILABLE</span> <span class="ow">and</span> <span class="n">REGEX_MODULE</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">re</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">exclusion_pattern</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Store in cache</span>
    <span class="n">_exclusion_pattern_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.basic.patterns.TokenizerPatterns.get_pattern" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">get_pattern</span><span class="p">(</span><span class="n">pattern_name</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Get compiled pattern by name.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h6 id="services.tokenizer.basic.patterns.TokenizerPatterns.get_pattern(pattern_name)" class="doc doc-heading doc-heading-parameter">                  <code>pattern_name</code>
</h6>            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the pattern to retrieve</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Compiled regex pattern</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="KeyError">KeyError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If pattern name is not found</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/patterns.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pattern_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get compiled pattern by name.</span>

<span class="sd">    Args:</span>
<span class="sd">        pattern_name: Name of the pattern to retrieve</span>

<span class="sd">    Returns:</span>
<span class="sd">        Compiled regex pattern</span>

<span class="sd">    Raises:</span>
<span class="sd">        KeyError: If pattern name is not found</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">pattern_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pattern &#39;</span><span class="si">{</span><span class="n">pattern_name</span><span class="si">}</span><span class="s2">&#39; not found&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="p">[</span><span class="n">pattern_name</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.basic.patterns.TokenizerPatterns.list_patterns" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">list_patterns</span><span class="p">()</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Get list of available pattern names.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/patterns.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">list_patterns</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get list of available pattern names.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="services.tokenizer.basic.patterns.get_patterns" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">get_patterns</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Get global TokenizerPatterns instance.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerPatterns&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.patterns.TokenizerPatterns&lt;/code&gt;)" href="#services.tokenizer.basic.patterns.TokenizerPatterns">TokenizerPatterns</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Singleton TokenizerPatterns instance</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/patterns.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_patterns</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">TokenizerPatterns</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get global TokenizerPatterns instance.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Singleton TokenizerPatterns instance</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">_global_patterns</span>
    <span class="k">if</span> <span class="n">_global_patterns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_global_patterns</span> <span class="o">=</span> <span class="n">TokenizerPatterns</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">_global_patterns</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>






<div class="doc doc-object doc-function">


<h3 id="services.tokenizer.basic.tokenize_text" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">tokenize_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Simple convenience function for basic text tokenization.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/__init__.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">tokenize_text</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">TokenizerConfig</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simple convenience function for basic text tokenization.&quot;&quot;&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">create_basic_tokenizer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-module">



<h3 id="services.tokenizer.basic.tokenizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <code>tokenizer</code>


</h3>

    <div class="doc doc-contents ">

        <p>BasicTokenizer implementation.</p>
<p>This module contains the main BasicTokenizer class that implements
Unicode-aware tokenization for social media text with entity preservation.</p>










<p><span class="doc-section-title">Classes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;BasicTokenizer&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.tokenizer.BasicTokenizer&lt;/code&gt;)" href="#services.tokenizer.basic.tokenizer.BasicTokenizer">BasicTokenizer</a></code></td>
            <td>
              <div class="doc-md-description">
                <p>Unicode-aware basic tokenizer for social media text.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>







<div class="doc doc-children">











<div class="doc doc-object doc-class">



<h4 id="services.tokenizer.basic.tokenizer.BasicTokenizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>BasicTokenizer</code>


</h4>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;AbstractTokenizer&lt;/code&gt; (&lt;code&gt;services.tokenizer.core.base.AbstractTokenizer&lt;/code&gt;)" href="#services.tokenizer.core.base.AbstractTokenizer">AbstractTokenizer</a></code></p>



        <p>Unicode-aware basic tokenizer for social media text.</p>
<p>This tokenizer handles mixed-script content, preserves social media entities
(@mentions, #hashtags, URLs), and applies appropriate tokenization strategies
for different script families.</p>












<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.tokenizer.BasicTokenizer.__init__&lt;/code&gt;)" href="#services.tokenizer.basic.tokenizer.BasicTokenizer.__init__">__init__</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Initialize BasicTokenizer with configuration.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-method&quot;&gt;&lt;/code&gt;            &lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt; (&lt;code&gt;services.tokenizer.basic.tokenizer.BasicTokenizer.tokenize&lt;/code&gt;)" href="#services.tokenizer.basic.tokenizer.BasicTokenizer.tokenize">tokenize</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Tokenize input text into a list of tokens.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>



              <details class="mkdocstrings-source">
                <summary>Source code in <code>services/tokenizer/basic/tokenizer.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BasicTokenizer</span><span class="p">(</span><span class="n">AbstractTokenizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unicode-aware basic tokenizer for social media text.</span>

<span class="sd">    This tokenizer handles mixed-script content, preserves social media entities</span>
<span class="sd">    (@mentions, #hashtags, URLs), and applies appropriate tokenization strategies</span>
<span class="sd">    for different script families.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TokenizerConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize BasicTokenizer with configuration.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: Tokenizer configuration. If None, default config will be used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span> <span class="o">=</span> <span class="n">get_patterns</span><span class="p">()</span>

        <span class="c1"># Compile regex pattern for character-level script detection (performance optimization)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_CHAR_LEVEL_PATTERN</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
            <span class="sa">r</span><span class="s2">&quot;[\u4e00-\u9fff&quot;</span>  <span class="c1"># CJK Unified Ideographs</span>
            <span class="sa">r</span><span class="s2">&quot;\u3400-\u4dbf&quot;</span>  <span class="c1"># CJK Extension A</span>
            <span class="sa">r</span><span class="s2">&quot;\u3040-\u309f&quot;</span>  <span class="c1"># Hiragana</span>
            <span class="sa">r</span><span class="s2">&quot;\u30a0-\u30ff&quot;</span>  <span class="c1"># Katakana</span>
            <span class="sa">r</span><span class="s2">&quot;\u0e00-\u0e7f&quot;</span>  <span class="c1"># Thai</span>
            <span class="sa">r</span><span class="s2">&quot;\u0e80-\u0eff&quot;</span>  <span class="c1"># Lao</span>
            <span class="sa">r</span><span class="s2">&quot;\u1000-\u109f&quot;</span>  <span class="c1"># Myanmar</span>
            <span class="sa">r</span><span class="s2">&quot;\u1780-\u17ff]&quot;</span>  <span class="c1"># Khmer</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tokenize input text into a list of tokens.</span>

<span class="sd">        Applies appropriate tokenization strategies for mixed-script content</span>
<span class="sd">        while preserving social media entities and handling Unicode correctly.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Input text to tokenize</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of tokens extracted from the input text in document order</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Apply preprocessing</span>
        <span class="n">processed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">processed_text</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Extract tokens using comprehensive regex pattern</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_tokens</span><span class="p">(</span><span class="n">processed_text</span><span class="p">)</span>

        <span class="c1"># Apply post-processing</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_postprocess_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_extract_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract tokens using comprehensive regex patterns.</span>
<span class="sd">        Preserves the original order of tokens as they appear in the input text.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Preprocessed text to tokenize</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of extracted tokens in their original order</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_tokens_ordered</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_char_level_script</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if character belongs to a character-level script.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_CHAR_LEVEL_PATTERN</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">char</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_get_char_script</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the script family for a character.</span>

<span class="sd">        Args:</span>
<span class="sd">            char: Character to analyze</span>

<span class="sd">        Returns:</span>
<span class="sd">            Script family name</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">code_point</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>

        <span class="c1"># Latin script</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="p">(</span><span class="mh">0x0041</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x007A</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="mh">0x00C0</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x024F</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="mh">0x1E00</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x1EFF</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;latin&quot;</span>

        <span class="c1"># Korean Hangul (space-separated, NOT character-level!)</span>
        <span class="k">elif</span> <span class="mh">0xAC00</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0xD7AF</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;korean&quot;</span>

        <span class="c1"># Character-level scripts (CJK, Thai, etc.)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">char</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;cjk&quot;</span>

        <span class="c1"># Arabic script</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="p">(</span><span class="mh">0x0600</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x06FF</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="mh">0x0750</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x077F</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="mh">0x08A0</span> <span class="o">&lt;=</span> <span class="n">code_point</span> <span class="o">&lt;=</span> <span class="mh">0x08FF</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;arabic&quot;</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;other&quot;</span>

    <span class="k">def</span> <span class="nf">_extract_tokens_ordered</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">language_family</span><span class="p">:</span> <span class="n">LanguageFamily</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract tokens preserving their original order in the text.</span>

<span class="sd">        Uses a single comprehensive regex pattern to find ALL tokens in document order,</span>
<span class="sd">        eliminating the need for complex segmentation and reassembly logic.</span>
<span class="sd">        This is the Phase 2 optimization that removes O(n×segments) complexity.</span>

<span class="sd">        Args:</span>
<span class="sd">            text: Preprocessed text to tokenize</span>
<span class="sd">            language_family: Detected language family for the full text</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of extracted tokens in their original order</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Remove excluded entities (URLs/emails) from text if they are disabled</span>
        <span class="c1"># This prevents them from being tokenized into component words</span>
        <span class="n">exclusion_pattern</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="o">.</span><span class="n">get_exclusion_pattern</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exclusion_pattern</span><span class="p">:</span>
            <span class="c1"># Replace excluded entities with spaces to maintain word boundaries</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">exclusion_pattern</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
            <span class="c1"># Clean up multiple spaces</span>
            <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Get comprehensive pattern based on configuration</span>
        <span class="c1"># This single pattern finds ALL tokens in document order</span>
        <span class="n">comprehensive_pattern</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span><span class="o">.</span><span class="n">get_comprehensive_pattern</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="p">)</span>

        <span class="c1"># Single regex call gets all tokens in order - this is the key optimization!</span>
        <span class="n">raw_tokens</span> <span class="o">=</span> <span class="n">comprehensive_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="c1"># If no tokens were found but input has content, use fallback for edge cases</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">raw_tokens</span> <span class="ow">and</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="c1"># For pure punctuation or unrecognized content, return as single token</span>
            <span class="c1"># This maintains compatibility with old tokenizer behavior for edge cases</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>

        <span class="c1"># Apply postprocessing for language-specific behavior and configuration filtering</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">raw_tokens</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                <span class="k">continue</span>

            <span class="c1"># Clean URLs by removing trailing punctuation</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_url_like</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
                <span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_clean_url_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

            <span class="c1"># For character-level scripts, break down multi-character tokens into individual characters</span>
            <span class="c1"># This maintains compatibility with existing test expectations</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">language_family</span> <span class="o">==</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">CJK</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_contains_char_level_chars</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># Only break down pure character-level tokens, not mixed tokens</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_pure_char_level_token</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
                    <span class="n">tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">token</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Mixed token - keep as is but process character-level parts</span>
                    <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">language_family</span> <span class="o">==</span> <span class="n">LanguageFamily</span><span class="o">.</span><span class="n">MIXED</span><span class="p">:</span>
                <span class="c1"># For mixed script, break down character-level script parts but keep Latin parts whole</span>
                <span class="n">processed_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_mixed_script_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
                <span class="n">tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">processed_tokens</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">_is_punctuation_only</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token contains only punctuation.&quot;&quot;&quot;</span>
        <span class="n">punctuation_chars</span> <span class="o">=</span> <span class="s2">&quot;.!?;:,()[]</span><span class="si">{}</span><span class="se">\&quot;</span><span class="s2">&#39;-~`@#$%^&amp;*+=&lt;&gt;/|</span><span class="se">\\</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">c</span> <span class="ow">in</span> <span class="n">punctuation_chars</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_numeric_only</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token is purely numeric.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">token</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;%&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;$&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">isdigit</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_url_like</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token looks like a URL.&quot;&quot;&quot;</span>
        <span class="c1"># Don&#39;t classify emails as URLs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_email_like</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Explicit URL indicators (http://, https://, www., or protocol markers)</span>
        <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;http://&quot;</span><span class="p">,</span> <span class="s2">&quot;https://&quot;</span><span class="p">,</span> <span class="s2">&quot;www.&quot;</span><span class="p">))</span> <span class="ow">or</span> <span class="s2">&quot;://&quot;</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># Domain-like patterns (e.g., &quot;example.com&quot;)</span>
        <span class="c1"># But NOT abbreviations (e.g., &quot;U.S.&quot;, &quot;c.e.o.s&quot;)</span>
        <span class="c1"># Heuristic: URLs have at least one period NOT followed by a single uppercase/lowercase letter</span>
        <span class="c1"># This allows &quot;example.com&quot; but excludes &quot;U.S.&quot; and &quot;c.e.o.s&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">token</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>
            <span class="ow">and</span> <span class="s2">&quot;@&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">token</span>
        <span class="p">):</span>
            <span class="c1"># Check if this looks like an abbreviation (single letters between periods)</span>
            <span class="c1"># Pattern: letter(s).letter(s).letter(s) where segments are 1-3 chars</span>
            <span class="n">abbreviation_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;^[a-z]{1,3}(?:\.[a-z]{1,3})+\.?$&quot;</span>

            <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">abbreviation_pattern</span><span class="p">,</span> <span class="n">token</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># This is an abbreviation, not a URL</span>
            <span class="c1"># If it has a period and looks like a domain, it&#39;s URL-like</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_is_email_like</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token looks like an email address.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;@&quot;</span> <span class="ow">in</span> <span class="n">token</span> <span class="ow">and</span> <span class="s2">&quot;.&quot;</span> <span class="ow">in</span> <span class="n">token</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">token</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;@&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_clean_url_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url_token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove trailing punctuation from URL tokens.&quot;&quot;&quot;</span>
        <span class="n">trailing_punctuation</span> <span class="o">=</span> <span class="s2">&quot;.!?;:,)]}</span><span class="se">\&quot;</span><span class="s2">&#39;&quot;</span>
        <span class="k">return</span> <span class="n">url_token</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="n">trailing_punctuation</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_contains_char_level_chars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token contains any character-level script characters.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_is_pure_char_level_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if token contains only character-level script characters.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="ow">or</span> <span class="n">char</span><span class="o">.</span><span class="n">isspace</span><span class="p">()</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_process_mixed_script_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process mixed script tokens by breaking down character-level script parts.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_contains_char_level_chars</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">token</span><span class="p">]</span>

        <span class="c1"># Check if token mixes Latin with CJK</span>
        <span class="n">has_latin</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">isascii</span><span class="p">()</span> <span class="ow">and</span> <span class="n">c</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>
        <span class="n">has_cjk</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">token</span><span class="p">)</span>

        <span class="c1"># Don&#39;t apply mixed-script preservation to social media entities</span>
        <span class="n">is_social_entity</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s2">&quot;@&quot;</span><span class="p">,</span> <span class="s2">&quot;#&quot;</span><span class="p">,</span> <span class="s2">&quot;$&quot;</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">has_latin</span> <span class="ow">and</span> <span class="n">has_cjk</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_social_entity</span><span class="p">:</span>
            <span class="c1"># Mixed script - keep intact (brand names, bot tricks)</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">token</span><span class="p">]</span>

        <span class="c1"># Rest of existing logic for pure CJK tokens...</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_token</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">current_is_cjk</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
            <span class="n">char_is_cjk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_char_level_script</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">current_is_cjk</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">current_is_cjk</span> <span class="o">=</span> <span class="n">char_is_cjk</span>
                <span class="n">current_token</span> <span class="o">=</span> <span class="n">char</span>
            <span class="k">elif</span> <span class="n">char_is_cjk</span> <span class="o">==</span> <span class="n">current_is_cjk</span><span class="p">:</span>
                <span class="n">current_token</span> <span class="o">+=</span> <span class="n">char</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Script change</span>
                <span class="k">if</span> <span class="n">current_token</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">current_is_cjk</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Break CJK into individual characters</span>
                        <span class="n">result</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">current_token</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span>
                <span class="n">current_token</span> <span class="o">=</span> <span class="n">char</span>
                <span class="n">current_is_cjk</span> <span class="o">=</span> <span class="n">char_is_cjk</span>

        <span class="c1"># Handle final token</span>
        <span class="k">if</span> <span class="n">current_token</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">current_is_cjk</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">current_token</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_token</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">_postprocess_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="n">TokenList</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply post-processing to extracted tokens.</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens: List of raw tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            Processed token list</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tokens</span>

        <span class="c1"># Apply base class post-processing (length filtering, whitespace stripping, etc.)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_postprocess_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.basic.tokenizer.BasicTokenizer.__init__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Initialize BasicTokenizer with configuration.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h6 id="services.tokenizer.basic.tokenizer.BasicTokenizer.__init__(config)" class="doc doc-heading doc-heading-parameter">                  <code>config</code>
</h6>            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;code&gt;TokenizerConfig&lt;/code&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-pydantic-model&quot;&gt;&lt;code&gt;pydantic-model&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;services.tokenizer.core.types.TokenizerConfig&lt;/code&gt;)" href="#services.tokenizer.core.types.TokenizerConfig">TokenizerConfig</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tokenizer configuration. If None, default config will be used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/tokenizer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TokenizerConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize BasicTokenizer with configuration.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: Tokenizer configuration. If None, default config will be used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_patterns</span> <span class="o">=</span> <span class="n">get_patterns</span><span class="p">()</span>

    <span class="c1"># Compile regex pattern for character-level script detection (performance optimization)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_CHAR_LEVEL_PATTERN</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="sa">r</span><span class="s2">&quot;[\u4e00-\u9fff&quot;</span>  <span class="c1"># CJK Unified Ideographs</span>
        <span class="sa">r</span><span class="s2">&quot;\u3400-\u4dbf&quot;</span>  <span class="c1"># CJK Extension A</span>
        <span class="sa">r</span><span class="s2">&quot;\u3040-\u309f&quot;</span>  <span class="c1"># Hiragana</span>
        <span class="sa">r</span><span class="s2">&quot;\u30a0-\u30ff&quot;</span>  <span class="c1"># Katakana</span>
        <span class="sa">r</span><span class="s2">&quot;\u0e00-\u0e7f&quot;</span>  <span class="c1"># Thai</span>
        <span class="sa">r</span><span class="s2">&quot;\u0e80-\u0eff&quot;</span>  <span class="c1"># Lao</span>
        <span class="sa">r</span><span class="s2">&quot;\u1000-\u109f&quot;</span>  <span class="c1"># Myanmar</span>
        <span class="sa">r</span><span class="s2">&quot;\u1780-\u17ff]&quot;</span>  <span class="c1"># Khmer</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h5 id="services.tokenizer.basic.tokenizer.BasicTokenizer.tokenize" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></code>

</h5>


    <div class="doc doc-contents ">

        <p>Tokenize input text into a list of tokens.</p>
<p>Applies appropriate tokenization strategies for mixed-script content
while preserving social media entities and handling Unicode correctly.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
<h6 id="services.tokenizer.basic.tokenizer.BasicTokenizer.tokenize(text)" class="doc doc-heading doc-heading-parameter">                  <code>text</code>
</h6>            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input text to tokenize</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="services.tokenizer.core.types.TokenList">TokenList</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of tokens extracted from the input text in document order</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>services/tokenizer/basic/tokenizer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenList</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenize input text into a list of tokens.</span>

<span class="sd">    Applies appropriate tokenization strategies for mixed-script content</span>
<span class="sd">    while preserving social media entities and handling Unicode correctly.</span>

<span class="sd">    Args:</span>
<span class="sd">        text: Input text to tokenize</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of tokens extracted from the input text in document order</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="c1"># Apply preprocessing</span>
    <span class="n">processed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">processed_text</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="c1"># Extract tokens using comprehensive regex pattern</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_tokens</span><span class="p">(</span><span class="n">processed_text</span><span class="p">)</span>

    <span class="c1"># Apply post-processing</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_postprocess_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>
















  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 CIB Mango Tree
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.path", "navigation.sections", "navigation.top", "content.code.copy", "content.tooltips", "toc.follow"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>